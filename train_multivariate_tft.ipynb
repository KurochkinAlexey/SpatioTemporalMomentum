{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b6afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import yfinance as yf\n",
    "from empyrical import sharpe_ratio\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.features import DeepMomentumFeatures, MACDFeatures, DatetimeFeatures, DefaultFeatureCreator\n",
    "from src.utils import MultivariateTrainValTestSplitter\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7d12f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009fa4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sectors_dict.pickle', 'rb') as f:\n",
    "    sectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db1873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_ASSETS_PER_SECTOR = 5\n",
    "LENGTH_THRESHOLD = 3000\n",
    "DATASET_DIRNAME = 'yf_data'\n",
    "USE_ADJUSTED_CLOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b9f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataframe shape (3068, 276)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "all_dfs = []\n",
    "all_used_assets = []\n",
    "for current_sector in sectors.keys():\n",
    "    dfs = []\n",
    "    assets = []\n",
    "    for asset in sectors[current_sector]:\n",
    "        df = pd.read_csv(os.path.join(DATASET_DIRNAME, f'{current_sector}', f'{asset}.csv'))\n",
    "        # use only stocks with long enough history\n",
    "        if len(df) > LENGTH_THRESHOLD:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            close_col = 'Adj Close' if USE_ADJUSTED_CLOSE else 'Close'\n",
    "            \n",
    "            cols = ['Date', 'Open', 'High', 'Low', close_col, 'Volume']\n",
    "            \n",
    "            df = df[cols]\n",
    "            \n",
    "            df.columns = ['Date'] + ['{}_{}'.format(asset, name) for name in \\\n",
    "                                     ['open', 'high', 'low', 'close', 'volume']]\n",
    "            dfs.append(df)\n",
    "            assets.append(asset)\n",
    "\n",
    "    df = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        df = pd.merge(df, dfs[i], left_on='Date', right_on='Date', how='inner')\n",
    "\n",
    "    used_assets = np.random.choice(assets, N_ASSETS_PER_SECTOR, replace=False)\n",
    "    df = df[['Date'] + [name for name in df.columns[1:] if name.split('_')[0] in used_assets]]\n",
    "    all_dfs.append(df)\n",
    "    all_used_assets.extend(list(used_assets))\n",
    "\n",
    "df = all_dfs[0]\n",
    "for i in range(1, len(all_dfs)):\n",
    "    df = pd.merge(df, all_dfs[i], left_on='Date', right_on='Date', how='inner')\n",
    "df = df.set_index(df['Date'])\n",
    "print('loaded dataframe shape', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2321c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ATVI_open</th>\n",
       "      <th>ATVI_high</th>\n",
       "      <th>ATVI_low</th>\n",
       "      <th>ATVI_close</th>\n",
       "      <th>ATVI_volume</th>\n",
       "      <th>GOOGL_open</th>\n",
       "      <th>GOOGL_high</th>\n",
       "      <th>GOOGL_low</th>\n",
       "      <th>GOOGL_close</th>\n",
       "      <th>...</th>\n",
       "      <th>SRE_open</th>\n",
       "      <th>SRE_high</th>\n",
       "      <th>SRE_low</th>\n",
       "      <th>SRE_close</th>\n",
       "      <th>SRE_volume</th>\n",
       "      <th>XEL_open</th>\n",
       "      <th>XEL_high</th>\n",
       "      <th>XEL_low</th>\n",
       "      <th>XEL_close</th>\n",
       "      <th>XEL_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-06-24</th>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>10.189775</td>\n",
       "      <td>16441800</td>\n",
       "      <td>12.029029</td>\n",
       "      <td>12.030781</td>\n",
       "      <td>11.837337</td>\n",
       "      <td>11.883884</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.195000</td>\n",
       "      <td>25.885000</td>\n",
       "      <td>12.255710</td>\n",
       "      <td>3270600</td>\n",
       "      <td>23.969999</td>\n",
       "      <td>24.180000</td>\n",
       "      <td>23.969999</td>\n",
       "      <td>16.178503</td>\n",
       "      <td>2162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-27</th>\n",
       "      <td>2011-06-27</td>\n",
       "      <td>11.270000</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>11.210000</td>\n",
       "      <td>10.271007</td>\n",
       "      <td>4798600</td>\n",
       "      <td>11.861862</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>11.851852</td>\n",
       "      <td>12.082082</td>\n",
       "      <td>...</td>\n",
       "      <td>25.969999</td>\n",
       "      <td>26.195000</td>\n",
       "      <td>25.959999</td>\n",
       "      <td>12.338344</td>\n",
       "      <td>2036000</td>\n",
       "      <td>24.120001</td>\n",
       "      <td>24.290001</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>16.306477</td>\n",
       "      <td>1412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-28</th>\n",
       "      <td>2011-06-28</td>\n",
       "      <td>11.390000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>10.460541</td>\n",
       "      <td>6695400</td>\n",
       "      <td>12.112613</td>\n",
       "      <td>12.417668</td>\n",
       "      <td>12.112613</td>\n",
       "      <td>12.353604</td>\n",
       "      <td>...</td>\n",
       "      <td>26.190001</td>\n",
       "      <td>26.235001</td>\n",
       "      <td>26.010000</td>\n",
       "      <td>12.293487</td>\n",
       "      <td>2512800</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>16.420980</td>\n",
       "      <td>1720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-29</th>\n",
       "      <td>2011-06-29</td>\n",
       "      <td>11.620000</td>\n",
       "      <td>11.760000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>10.550797</td>\n",
       "      <td>6435300</td>\n",
       "      <td>12.425926</td>\n",
       "      <td>12.518769</td>\n",
       "      <td>12.321822</td>\n",
       "      <td>12.451702</td>\n",
       "      <td>...</td>\n",
       "      <td>26.139999</td>\n",
       "      <td>26.205000</td>\n",
       "      <td>25.985001</td>\n",
       "      <td>12.347787</td>\n",
       "      <td>2127600</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>16.420980</td>\n",
       "      <td>2013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-30</th>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>11.740000</td>\n",
       "      <td>11.790000</td>\n",
       "      <td>11.670000</td>\n",
       "      <td>10.541772</td>\n",
       "      <td>6501800</td>\n",
       "      <td>12.562312</td>\n",
       "      <td>12.679429</td>\n",
       "      <td>12.550050</td>\n",
       "      <td>12.672172</td>\n",
       "      <td>...</td>\n",
       "      <td>26.260000</td>\n",
       "      <td>26.459999</td>\n",
       "      <td>26.049999</td>\n",
       "      <td>12.484720</td>\n",
       "      <td>2234200</td>\n",
       "      <td>24.469999</td>\n",
       "      <td>24.469999</td>\n",
       "      <td>24.230000</td>\n",
       "      <td>16.367092</td>\n",
       "      <td>4290900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-28</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>91.809998</td>\n",
       "      <td>92.010002</td>\n",
       "      <td>91.750000</td>\n",
       "      <td>91.769997</td>\n",
       "      <td>5527200</td>\n",
       "      <td>131.309998</td>\n",
       "      <td>132.539993</td>\n",
       "      <td>130.139999</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>...</td>\n",
       "      <td>71.660004</td>\n",
       "      <td>72.080002</td>\n",
       "      <td>71.330002</td>\n",
       "      <td>71.559998</td>\n",
       "      <td>1600500</td>\n",
       "      <td>57.860001</td>\n",
       "      <td>58.150002</td>\n",
       "      <td>57.650002</td>\n",
       "      <td>57.849998</td>\n",
       "      <td>3982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>91.750000</td>\n",
       "      <td>92.099998</td>\n",
       "      <td>91.750000</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>5667900</td>\n",
       "      <td>132.240005</td>\n",
       "      <td>136.570007</td>\n",
       "      <td>132.240005</td>\n",
       "      <td>134.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>71.739998</td>\n",
       "      <td>72.089996</td>\n",
       "      <td>71.199997</td>\n",
       "      <td>71.709999</td>\n",
       "      <td>1777400</td>\n",
       "      <td>57.779999</td>\n",
       "      <td>58.340000</td>\n",
       "      <td>57.509998</td>\n",
       "      <td>57.950001</td>\n",
       "      <td>4614900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-30</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>91.879997</td>\n",
       "      <td>92.040001</td>\n",
       "      <td>91.750000</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>5359700</td>\n",
       "      <td>134.779999</td>\n",
       "      <td>136.279999</td>\n",
       "      <td>134.070007</td>\n",
       "      <td>135.880005</td>\n",
       "      <td>...</td>\n",
       "      <td>71.510002</td>\n",
       "      <td>71.820000</td>\n",
       "      <td>70.580002</td>\n",
       "      <td>70.849998</td>\n",
       "      <td>1938700</td>\n",
       "      <td>57.880001</td>\n",
       "      <td>58.240002</td>\n",
       "      <td>57.419998</td>\n",
       "      <td>57.680000</td>\n",
       "      <td>2583500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-31</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>91.879997</td>\n",
       "      <td>92.059998</td>\n",
       "      <td>91.870003</td>\n",
       "      <td>91.989998</td>\n",
       "      <td>6676500</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>135.789993</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>...</td>\n",
       "      <td>71.099998</td>\n",
       "      <td>71.410004</td>\n",
       "      <td>70.150002</td>\n",
       "      <td>70.220001</td>\n",
       "      <td>3408400</td>\n",
       "      <td>57.959999</td>\n",
       "      <td>58.080002</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>57.130001</td>\n",
       "      <td>3983700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>92.050003</td>\n",
       "      <td>92.199997</td>\n",
       "      <td>91.949997</td>\n",
       "      <td>92.040001</td>\n",
       "      <td>4605700</td>\n",
       "      <td>137.460007</td>\n",
       "      <td>137.460007</td>\n",
       "      <td>134.850006</td>\n",
       "      <td>135.660004</td>\n",
       "      <td>...</td>\n",
       "      <td>70.730003</td>\n",
       "      <td>70.910004</td>\n",
       "      <td>69.510002</td>\n",
       "      <td>70.059998</td>\n",
       "      <td>1804000</td>\n",
       "      <td>57.490002</td>\n",
       "      <td>57.529999</td>\n",
       "      <td>56.080002</td>\n",
       "      <td>56.509998</td>\n",
       "      <td>2848100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3068 rows × 276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  ATVI_open  ATVI_high   ATVI_low  ATVI_close  \\\n",
       "Date                                                                 \n",
       "2011-06-24 2011-06-24  11.490000  11.490000  11.250000   10.189775   \n",
       "2011-06-27 2011-06-27  11.270000  11.490000  11.210000   10.271007   \n",
       "2011-06-28 2011-06-28  11.390000  11.600000  11.330000   10.460541   \n",
       "2011-06-29 2011-06-29  11.620000  11.760000  11.500000   10.550797   \n",
       "2011-06-30 2011-06-30  11.740000  11.790000  11.670000   10.541772   \n",
       "...               ...        ...        ...        ...         ...   \n",
       "2023-08-28 2023-08-28  91.809998  92.010002  91.750000   91.769997   \n",
       "2023-08-29 2023-08-29  91.750000  92.099998  91.750000   91.980003   \n",
       "2023-08-30 2023-08-30  91.879997  92.040001  91.750000   91.980003   \n",
       "2023-08-31 2023-08-31  91.879997  92.059998  91.870003   91.989998   \n",
       "2023-09-01 2023-09-01  92.050003  92.199997  91.949997   92.040001   \n",
       "\n",
       "            ATVI_volume  GOOGL_open  GOOGL_high   GOOGL_low  GOOGL_close  ...  \\\n",
       "Date                                                                      ...   \n",
       "2011-06-24     16441800   12.029029   12.030781   11.837337    11.883884  ...   \n",
       "2011-06-27      4798600   11.861862   12.222222   11.851852    12.082082  ...   \n",
       "2011-06-28      6695400   12.112613   12.417668   12.112613    12.353604  ...   \n",
       "2011-06-29      6435300   12.425926   12.518769   12.321822    12.451702  ...   \n",
       "2011-06-30      6501800   12.562312   12.679429   12.550050    12.672172  ...   \n",
       "...                 ...         ...         ...         ...          ...  ...   \n",
       "2023-08-28      5527200  131.309998  132.539993  130.139999   131.009995  ...   \n",
       "2023-08-29      5667900  132.240005  136.570007  132.240005   134.570007  ...   \n",
       "2023-08-30      5359700  134.779999  136.279999  134.070007   135.880005  ...   \n",
       "2023-08-31      6676500  136.009995  138.000000  135.789993   136.169998  ...   \n",
       "2023-09-01      4605700  137.460007  137.460007  134.850006   135.660004  ...   \n",
       "\n",
       "             SRE_open   SRE_high    SRE_low  SRE_close  SRE_volume   XEL_open  \\\n",
       "Date                                                                            \n",
       "2011-06-24  26.000000  26.195000  25.885000  12.255710     3270600  23.969999   \n",
       "2011-06-27  25.969999  26.195000  25.959999  12.338344     2036000  24.120001   \n",
       "2011-06-28  26.190001  26.235001  26.010000  12.293487     2512800  24.320000   \n",
       "2011-06-29  26.139999  26.205000  25.985001  12.347787     2127600  24.459999   \n",
       "2011-06-30  26.260000  26.459999  26.049999  12.484720     2234200  24.469999   \n",
       "...               ...        ...        ...        ...         ...        ...   \n",
       "2023-08-28  71.660004  72.080002  71.330002  71.559998     1600500  57.860001   \n",
       "2023-08-29  71.739998  72.089996  71.199997  71.709999     1777400  57.779999   \n",
       "2023-08-30  71.510002  71.820000  70.580002  70.849998     1938700  57.880001   \n",
       "2023-08-31  71.099998  71.410004  70.150002  70.220001     3408400  57.959999   \n",
       "2023-09-01  70.730003  70.910004  69.510002  70.059998     1804000  57.490002   \n",
       "\n",
       "             XEL_high    XEL_low  XEL_close  XEL_volume  \n",
       "Date                                                     \n",
       "2011-06-24  24.180000  23.969999  16.178503     2162800  \n",
       "2011-06-27  24.290001  24.100000  16.306477     1412500  \n",
       "2011-06-28  24.459999  24.190001  16.420980     1720100  \n",
       "2011-06-29  24.459999  24.350000  16.420980     2013700  \n",
       "2011-06-30  24.469999  24.230000  16.367092     4290900  \n",
       "...               ...        ...        ...         ...  \n",
       "2023-08-28  58.150002  57.650002  57.849998     3982200  \n",
       "2023-08-29  58.340000  57.509998  57.950001     4614900  \n",
       "2023-08-30  58.240002  57.419998  57.680000     2583500  \n",
       "2023-08-31  58.080002  57.110001  57.130001     3983700  \n",
       "2023-09-01  57.529999  56.080002  56.509998     2848100  \n",
       "\n",
       "[3068 rows x 276 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f66d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DATETIME_FEATURES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22d72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = [DeepMomentumFeatures, MACDFeatures]\n",
    "features_configs = [{}, {}]\n",
    "if USE_DATETIME_FEATURES:\n",
    "    used_features.append(DatetimeFeatures)\n",
    "    features_configs.append({})\n",
    "\n",
    "fc = DefaultFeatureCreator(df, all_used_assets, used_features, features_configs)\n",
    "\n",
    "features = fc.create_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8323dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_VALUES_THRESHOLD = 10000\n",
    "for key in features.keys():\n",
    "    assert features[key].isnull().sum().sum() == 0\n",
    "    assert features[key].max().max() < BAD_VALUES_THRESHOLD\n",
    "    assert features[key].min().min() > -BAD_VALUES_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d821280",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['norm_daily_return',\n",
    "               'norm_monthly_return',\n",
    "               'norm_quarterly_return',\n",
    "               'norm_biannual_return',\n",
    "               'norm_annual_return',\n",
    "               'macd_8_24',\n",
    "               'macd_16_48',\n",
    "               'macd_32_96']\n",
    "\n",
    "if USE_DATETIME_FEATURES:\n",
    "    datetime_cols = ['day_of_week', 'day_of_month', 'month_of_year']\n",
    "    \n",
    "    for col in datetime_cols:\n",
    "        if key in features.keys():\n",
    "            features[key][col] = LabelEncoder().fit_transform(features[key][col])\n",
    "else:\n",
    "    datetime_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6bb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Dict, List, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module: nn.Module, batch_first: bool = False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "        return y\n",
    "\n",
    "\n",
    "class TimeDistributedInterpolation(nn.Module):\n",
    "    def __init__(self, output_size: int, batch_first: bool = False, trainable: bool = False):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.trainable = trainable\n",
    "        if self.trainable:\n",
    "            self.mask = nn.Parameter(torch.zeros(self.output_size, dtype=torch.float32))\n",
    "            self.gate = nn.Sigmoid()\n",
    "\n",
    "    def interpolate(self, x):\n",
    "        upsampled = F.interpolate(x.unsqueeze(1), self.output_size, mode=\"linear\", align_corners=True).squeeze(1)\n",
    "        if self.trainable:\n",
    "            upsampled = upsampled * self.gate(self.mask.unsqueeze(0)) * 2.0\n",
    "        return upsampled\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.interpolate(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.interpolate(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class GatedLinearUnit(nn.Module):\n",
    "    \"\"\"Gated Linear Unit\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int = None, dropout: float = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = dropout\n",
    "        self.hidden_size = hidden_size or input_size\n",
    "        self.fc = nn.Linear(input_size, self.hidden_size * 2)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for n, p in self.named_parameters():\n",
    "            if \"bias\" in n:\n",
    "                torch.nn.init.zeros_(p)\n",
    "            elif \"fc\" in n:\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "\n",
    "                \n",
    "    def forward(self, x):\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = F.glu(x, dim=-1)\n",
    "        return x    \n",
    "    \n",
    "\n",
    "class ResampleNorm(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int = None, trainable_add: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.trainable_add = trainable_add\n",
    "        self.output_size = output_size or input_size\n",
    "\n",
    "        if self.input_size != self.output_size:\n",
    "            self.resample = TimeDistributedInterpolation(self.output_size, batch_first=True, trainable=False)\n",
    "\n",
    "        if self.trainable_add:\n",
    "            self.mask = nn.Parameter(torch.zeros(self.output_size, dtype=torch.float))\n",
    "            self.gate = nn.Sigmoid()\n",
    "        self.norm = nn.LayerNorm(self.output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.input_size != self.output_size:\n",
    "            x = self.resample(x)\n",
    "\n",
    "        if self.trainable_add:\n",
    "            x = x * self.gate(self.mask) * 2.0\n",
    "        output = self.norm(x)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, input_size: int, skip_size: int = None, trainable_add: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.trainable_add = trainable_add\n",
    "        self.skip_size = skip_size or input_size\n",
    "        \n",
    "        assert self.input_size == self.skip_size\n",
    "        \n",
    "        if self.input_size != self.skip_size:\n",
    "            self.resample = TimeDistributedInterpolation(self.input_size, batch_first=True, trainable=False)\n",
    "\n",
    "        if self.trainable_add:\n",
    "            self.mask = nn.Parameter(torch.zeros(self.input_size, dtype=torch.float))\n",
    "            self.gate = nn.Sigmoid()\n",
    "        self.norm = nn.LayerNorm(self.input_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, skip: torch.Tensor):\n",
    "        if self.input_size != self.skip_size:\n",
    "            skip = self.resample(skip)\n",
    "\n",
    "        if self.trainable_add:\n",
    "            skip = skip * self.gate(self.mask) * 2.0\n",
    "\n",
    "        output = self.norm(x + skip)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class GateAddNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int = None,\n",
    "        skip_size: int = None,\n",
    "        trainable_add: bool = False,\n",
    "        dropout: float = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size or input_size\n",
    "        self.skip_size = skip_size or self.hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.glu = GatedLinearUnit(self.input_size, hidden_size=self.hidden_size, dropout=self.dropout)\n",
    "        self.add_norm = AddNorm(self.hidden_size, skip_size=self.skip_size, trainable_add=trainable_add)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        output = self.glu(x)\n",
    "        output = self.add_norm(output, skip)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        dropout: float = 0.1,\n",
    "        context_size: int = None,\n",
    "        residual: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.context_size = context_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.residual = residual\n",
    "\n",
    "        if self.input_size != self.output_size and not self.residual:\n",
    "            residual_size = self.input_size\n",
    "        else:\n",
    "            residual_size = self.output_size\n",
    "\n",
    "        if self.output_size != residual_size:\n",
    "            self.resample_norm = ResampleNorm(residual_size, self.output_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "        if self.context_size is not None:\n",
    "            self.context = nn.Linear(self.context_size, self.hidden_size, bias=False)\n",
    "\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.init_weights()\n",
    "\n",
    "        self.gate_norm = GateAddNorm(\n",
    "            input_size=self.hidden_size,\n",
    "            skip_size=self.output_size,\n",
    "            hidden_size=self.output_size,\n",
    "            dropout=self.dropout,\n",
    "            trainable_add=False,\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, p in self.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                torch.nn.init.zeros_(p)\n",
    "            elif \"fc1\" in name or \"fc2\" in name:\n",
    "                torch.nn.init.kaiming_normal_(p, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")\n",
    "            elif \"context\" in name:\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x, context=None, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "\n",
    "        if self.input_size != self.output_size and not self.residual:\n",
    "            residual = self.resample_norm(residual)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        if context is not None:\n",
    "            context = self.context(context)\n",
    "            x = x + context\n",
    "        x = self.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gate_norm(x, residual)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class VariableSelectionNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cont_input_sizes: List[int],\n",
    "        cat_input_sizes: List[int],\n",
    "        hidden_size: int,\n",
    "        dropout: float = 0.1,\n",
    "        \n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calcualte weights for ``num_inputs`` variables  which are each of size ``input_size``\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.cont_input_sizes = cont_input_sizes\n",
    "        self.cat_input_sizes = cat_input_sizes\n",
    "        \n",
    "        self.input_sizes = self.cont_input_sizes + self.cat_input_sizes\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        input_size_total = sum(cont_input_sizes+cat_input_sizes)\n",
    "        \n",
    "        num_inputs = len(cont_input_sizes+cat_input_sizes)\n",
    "        \n",
    "        self.flattened_grn = GatedResidualNetwork(\n",
    "                    input_size_total,\n",
    "                    min(self.hidden_size, num_inputs),\n",
    "                    num_inputs,\n",
    "                    self.dropout,\n",
    "                    residual=False,\n",
    "                )\n",
    "                \n",
    "\n",
    "        self.single_variable_grns = nn.ModuleList()\n",
    "        \n",
    "        for input_size in self.input_sizes:\n",
    "            \n",
    "            self.single_variable_grns.append(GatedResidualNetwork(\n",
    "                input_size,\n",
    "                min(input_size, self.hidden_size),\n",
    "                output_size=self.hidden_size,\n",
    "                dropout=self.dropout,\n",
    "            ))\n",
    "            \n",
    "\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x: List[torch.Tensor],\n",
    "                x_cat: List[torch.Tensor]):\n",
    "        \n",
    "        # transform single variables\n",
    "        var_outputs = []\n",
    "        weight_inputs = []\n",
    "        for j, elem in enumerate(x+x_cat):\n",
    "            # select embedding belonging to a single input\n",
    "            \n",
    "            weight_inputs.append(elem)\n",
    "            var_outputs.append(self.single_variable_grns[j](elem))\n",
    "        var_outputs = torch.stack(var_outputs, dim=-1)\n",
    "\n",
    "        # calculate variable weights\n",
    "        flat_embedding = torch.cat(weight_inputs, dim=-1)\n",
    "        sparse_weights = self.flattened_grn(flat_embedding, context=None)\n",
    "        sparse_weights = self.softmax(sparse_weights).unsqueeze(-2)\n",
    "\n",
    "        outputs = var_outputs * sparse_weights\n",
    "        outputs = outputs.sum(dim=-1)\n",
    "        \n",
    "        return outputs, sparse_weights\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout: float = None, scale: bool = True):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = dropout\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        attn = torch.bmm(q, k.permute(0, 2, 1))  # query-key overlap\n",
    "\n",
    "        if self.scale:\n",
    "            dimension = torch.as_tensor(k.size(-1), dtype=attn.dtype, device=attn.device).sqrt()\n",
    "            attn = attn / dimension\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -1e9)\n",
    "        attn = self.softmax(attn)\n",
    "\n",
    "        if self.dropout is not None:\n",
    "            attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "        return output, attn\n",
    "\n",
    "    \n",
    "class InterpretableMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head: int, d_model: int, dropout: float = 0.0):\n",
    "        super(InterpretableMultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_k = self.d_q = self.d_v = d_model // n_head\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.v_layer = nn.Linear(self.d_model, self.d_v)\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(self.d_model, self.d_q) for _ in range(self.n_head)])\n",
    "        self.k_layers = nn.ModuleList([nn.Linear(self.d_model, self.d_k) for _ in range(self.n_head)])\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "        self.w_h = nn.Linear(self.d_v, self.d_model, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, p in self.named_parameters():\n",
    "            if \"bias\" not in name:\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "            else:\n",
    "                torch.nn.init.zeros_(p)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        heads = []\n",
    "        attns = []\n",
    "        vs = self.v_layer(v)\n",
    "        \n",
    "        for i in range(self.n_head):\n",
    "            qs = self.q_layers[i](q)\n",
    "            ks = self.k_layers[i](k)\n",
    "            head, attn = self.attention(qs, ks, vs, mask)\n",
    "            head_dropout = self.dropout(head)\n",
    "            heads.append(head_dropout)\n",
    "            attns.append(attn)\n",
    "\n",
    "        head = torch.stack(heads, dim=2) if self.n_head > 1 else heads[0]\n",
    "        attn = torch.stack(attns, dim=2)\n",
    "\n",
    "        outputs = torch.mean(head, dim=2) if self.n_head > 1 else head\n",
    "        outputs = self.w_h(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "\n",
    "        return outputs, attn    \n",
    "    \n",
    "\n",
    "class TFT(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, timesteps, cat_info=None, emb_dim=16, prescale_dim=16, \n",
    "                 hidden_dim=32, n_heads=4, dropout=0.1, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        cat_info = {} if cat_info is None else cat_info\n",
    "        \n",
    "        if cat_info:\n",
    "            self.embeddings_enc = nn.ModuleList([nn.Embedding(nunique, emb_dim) for nunique in cat_info.values()])\n",
    "            self.embeddings_dec = nn.ModuleList([nn.Embedding(nunique, emb_dim) for nunique in cat_info.values()])\n",
    "        else:\n",
    "            self.embeddings_enc = []\n",
    "            self.embeddings_dec = []\n",
    "            \n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.n_heads = n_heads\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.prescalers_enc = nn.ModuleList([nn.Linear(1, prescale_dim) for _ in range(input_dim)])\n",
    "        self.prescalers_dec = nn.ModuleList([nn.Linear(1, prescale_dim) for _ in range(input_dim)])\n",
    "        \n",
    "        self.vsn_enc = VariableSelectionNetwork([prescale_dim for _ in range(input_dim)], \n",
    "                                                [emb_dim for _ in range(len(cat_info.keys()))],\n",
    "                                                hidden_dim,\n",
    "                                                dropout=dropout,\n",
    "                                                )\n",
    "        self.vsn_dec = VariableSelectionNetwork([prescale_dim for _ in range(input_dim)], \n",
    "                                                [emb_dim for _ in range(len(cat_info.keys()))],\n",
    "                                                hidden_dim,\n",
    "                                                dropout=dropout,\n",
    "                                                )\n",
    "        \n",
    "        \n",
    "        self.lstm_encoder = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            \n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.lstm_decoder = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            \n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.post_lstm_gate_encoder = GatedLinearUnit(self.hidden_dim, dropout=self.dropout)\n",
    "        self.post_lstm_gate_decoder = self.post_lstm_gate_encoder #shared\n",
    "        \n",
    "        self.post_lstm_add_norm_encoder = AddNorm(self.hidden_dim, trainable_add=False)\n",
    "        self.post_lstm_add_norm_decoder = self.post_lstm_add_norm_encoder #shared\n",
    "        \n",
    "        \n",
    "        self.multihead_attn = InterpretableMultiHeadAttention(\n",
    "            d_model=self.hidden_dim, n_head=self.n_heads, dropout=self.dropout\n",
    "        )\n",
    "        \n",
    "        self.post_attn_gate_norm = GateAddNorm(\n",
    "            self.hidden_dim, dropout=self.dropout, trainable_add=False\n",
    "        )\n",
    "        \n",
    "        self.pos_wise_ff = GatedResidualNetwork(\n",
    "            self.hidden_dim, self.hidden_dim, self.hidden_dim, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        self.pre_output_gate_norm = GateAddNorm(self.hidden_dim, dropout=None, trainable_add=False)\n",
    "\n",
    "        \n",
    "        self.output_layer = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    \n",
    "    def get_attention_mask(self, encoder_lengths: torch.LongTensor, decoder_lengths: torch.LongTensor):\n",
    "\n",
    "        decoder_length = decoder_lengths.max()\n",
    "\n",
    "        attend_step = torch.arange(decoder_length, device=self.device)\n",
    "        predict_step = torch.arange(0, decoder_length, device=self.device)[:, None]\n",
    "        decoder_mask = (attend_step >= predict_step).unsqueeze(0).expand(encoder_lengths.size(0), -1, -1)\n",
    "       \n",
    "        encoder_mask = self.create_mask(encoder_lengths.max(), encoder_lengths).unsqueeze(1).expand(-1, decoder_length, -1)\n",
    "        \n",
    "        mask = torch.cat([encoder_mask, decoder_mask], dim=2)\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    \n",
    "    def create_mask(self, size: int, lengths: torch.LongTensor, inverse: bool = False) -> torch.BoolTensor:\n",
    "\n",
    "        if inverse:  \n",
    "            return torch.arange(size, device=lengths.device).unsqueeze(0) < lengths.unsqueeze(-1)\n",
    "        else:  \n",
    "            return torch.arange(size, device=lengths.device).unsqueeze(0) >= lengths.unsqueeze(-1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_enc, x_cat_enc, x_dec, x_cat_dec, enc_length, dec_length):\n",
    "    \n",
    "        \n",
    "        cat_embs_enc = []\n",
    "        cat_embs_dec = []\n",
    "        if self.embeddings_enc:\n",
    "            \n",
    "            for i in range(x_cat_enc.shape[2]):\n",
    "                y_enc = self.embeddings_enc[i](x_cat_enc[..., i])\n",
    "                y_dec = self.embeddings_dec[i](x_cat_dec[..., i])\n",
    "                cat_embs_enc.append(y_enc)\n",
    "                cat_embs_dec.append(y_dec)\n",
    "            \n",
    "            \n",
    "        scaled_x_enc = []\n",
    "        scaled_x_dec = []\n",
    "\n",
    "        for i in range(self.input_dim):\n",
    "            x_sc_enc = self.prescalers_enc[i](x_enc[..., i:i+1])\n",
    "            scaled_x_enc.append(x_sc_enc)\n",
    "\n",
    "            x_sc_dec = self.prescalers_dec[i](x_dec[..., i:i+1])\n",
    "            scaled_x_dec.append(x_sc_dec)\n",
    "    \n",
    "        vsn_enc, weight_enc = self.vsn_enc(scaled_x_enc, cat_embs_enc)\n",
    "        vsn_dec, weight_dec = self.vsn_dec(scaled_x_dec, cat_embs_dec)\n",
    "        \n",
    "        encoder_output, (hidden, cell) = self.lstm_encoder(vsn_enc)\n",
    "\n",
    "        decoder_output, _ = self.lstm_decoder(vsn_dec, (hidden, cell))\n",
    "        \n",
    "        lstm_output_encoder = self.post_lstm_gate_encoder(encoder_output)\n",
    "        lstm_output_encoder = self.post_lstm_add_norm_encoder(lstm_output_encoder, vsn_enc)\n",
    "\n",
    "        lstm_output_decoder = self.post_lstm_gate_decoder(decoder_output)\n",
    "        lstm_output_decoder = self.post_lstm_add_norm_decoder(lstm_output_decoder, vsn_dec)\n",
    "\n",
    "        lstm_output = torch.cat([lstm_output_encoder, lstm_output_decoder], dim=1)\n",
    "        \n",
    "        attn_output, attn_output_weights = self.multihead_attn(\n",
    "            q=lstm_output[:, x_enc.shape[1]:],  \n",
    "            k=lstm_output,\n",
    "            v=lstm_output,\n",
    "            mask=self.get_attention_mask(encoder_lengths=enc_length, decoder_lengths=dec_length),\n",
    "        )\n",
    "\n",
    "        attn_output = self.post_attn_gate_norm(attn_output, lstm_output[:, x_enc.shape[1]:])\n",
    "\n",
    "        output = self.pos_wise_ff(attn_output)\n",
    "\n",
    "        output = self.pre_output_gate_norm(output, lstm_output[:, x_enc.shape[1]:])\n",
    "        output = self.output_layer(output)\n",
    "        \n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bb6eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAPPING = {'lstm': LSTMnet,\n",
    "                 'slp': SLP,\n",
    "                 'mlp': MLP,\n",
    "                 'conv': TCN,\n",
    "                 'tft': TFT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a8da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = None #'standard', 'minmax'\n",
    "history_size = 63\n",
    "encoder_length = 42 #None for non TFT model\n",
    "val_delta = pd.Timedelta('365days')\n",
    "test_delta = pd.Timedelta('365days')\n",
    "date_range = pd.date_range('2017-01-01', '2023-12-31', freq='365d')\n",
    "model_type = 'tft' \n",
    "model_params = {}\n",
    "apply_turnover_reg = False\n",
    "apply_l1_reg = False\n",
    "weight_decay = 1e-5\n",
    "lr = 1e-3\n",
    "decay_steps = 10\n",
    "decay_gamma = 0.75\n",
    "early_stopping_rounds = 10\n",
    "n_epochs = 200\n",
    "device = 'cpu'\n",
    "target_vol = 0.15 #measure for turnover evaluation\n",
    "basis_points = [0, 1, 5, 10] #coefficients for turnover evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef99fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import abc\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "    \n",
    "class TrainValTestSplitter(abc.ABC):\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def split(self, start, val_delta, test_delta, seed):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class MultivariateTrainValTestSplitter(TrainValTestSplitter):\n",
    "    def __init__(self, data, cols, cat_cols, target_col, orig_returns_col, vol_col,\n",
    "                 timesteps=63, scaling=None, batch_size=64, encoder_length=None):\n",
    "        self._data = deepcopy(data)\n",
    "        self._cols = cols\n",
    "        self._cat_cols = cat_cols\n",
    "        self._target_col = target_col\n",
    "        self._orig_returns_col = orig_returns_col\n",
    "        self._vol_col = vol_col\n",
    "        self._scaling = scaling\n",
    "        self._scalers = {}\n",
    "        self._timesteps = timesteps\n",
    "        self._batch_size= batch_size\n",
    "        self._encoder_length = encoder_length\n",
    "        \n",
    "       # assert len(datetime_cols) == 0\n",
    "        assert self._target_col not in self._cols\n",
    "        assert self._orig_returns_col not in self._cols\n",
    "       # assert self._vol_col not in self._cols\n",
    "        \n",
    "        \n",
    "    def split(self, start, val_delta, test_delta, seed):        \n",
    "        \n",
    "        offset_delta = pd.Timedelta('1day')\n",
    "        \n",
    "        X_train, X_val, X_test = [], [], []\n",
    "        y_train, y_val, y_test = [], [], []\n",
    "        y_train_orig, y_val_orig, y_test_orig = [], [], []\n",
    "        vol_train, vol_val, vol_test = [], [], []\n",
    "        \n",
    "        test_datetimes = []\n",
    "        datetime_features_created = False\n",
    "        \n",
    "        for key in self._data.keys():\n",
    "            self._data[key]['idx'] = np.arange(len(self._data[key]))\n",
    "            train_val_test = self._data[key].loc[:start+val_delta+test_delta]\n",
    "            \n",
    "            \n",
    "            # optionally scale features\n",
    "            if self._scaling is not None:\n",
    "                if self._scaling == 'minmax':\n",
    "                    scaler = MinMaxScaler().fit(train_val_test.loc[:start, self._cols])\n",
    "                elif self._scaling == 'standard':\n",
    "                    scaler = StandardScaler().fit(train_val_test.loc[:start, self._cols])\n",
    "                \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                \n",
    "                self._scalers[(start, key)] = scaler\n",
    "\n",
    "                train_val_test.loc[:, self._cols] = scaler.transform(train_val_test.loc[:, self._cols])\n",
    "\n",
    "            cols = self._cols\n",
    "            \n",
    "            target_timesteps = self._timesteps\n",
    "            if self._encoder_length is not None:\n",
    "                target_timesteps -= self._encoder_length\n",
    "            \n",
    "            X = np.zeros((len(train_val_test), self._timesteps, len(cols)))\n",
    "            y = np.zeros((len(train_val_test), target_timesteps, 1))\n",
    "\n",
    "            #collect non scaled target returns data for further model evaluation\n",
    "            y_orig = np.zeros((len(train_val_test), target_timesteps, 1))\n",
    "            #collect volatility data for turnover regularization and/or evaluation\n",
    "            vol = np.zeros((len(train_val_test), target_timesteps, 1))\n",
    "            \n",
    "            for i, col in enumerate(cols):\n",
    "                for j in range(self._timesteps):\n",
    "                    X[:, j, i] = train_val_test[col].shift(self._timesteps - j - 1)\n",
    "                    \n",
    "\n",
    "            for j in range(target_timesteps):\n",
    "                y[:, j, 0] = train_val_test[self._target_col].shift(target_timesteps - j - 1)\n",
    "                y_orig[:, j, 0] = train_val_test[self._orig_returns_col].shift(target_timesteps - j - 1)\n",
    "                vol[:, j, 0] = train_val_test[self._vol_col].shift(target_timesteps - j - 1)\n",
    "                \n",
    "            \n",
    "            train_idx = train_val_test.loc[:start, 'idx']\n",
    "            val_idx = train_val_test.loc[start+offset_delta:start+val_delta, 'idx']\n",
    "            test_idx = train_val_test.loc[start+val_delta+offset_delta:start+val_delta+test_delta, 'idx']\n",
    "            \n",
    "            val_dt = train_val_test.loc[train_val_test['idx'].isin(val_idx)].index\n",
    "            test_dt = train_val_test.loc[train_val_test['idx'].isin(test_idx)].index\n",
    "            test_datetimes.append(test_dt)\n",
    "            \n",
    "            X_train_, y_train_, y_train_orig_, vol_train_ = \\\n",
    "                                X[train_idx], y[train_idx], y_orig[train_idx], vol[train_idx]\n",
    "            X_val_, y_val_, y_val_orig_, vol_val_ = \\\n",
    "                                X[val_idx], y[val_idx], y_orig[val_idx], vol[val_idx]\n",
    "            \n",
    "            X_test_, y_test_, y_test_orig_, vol_test_ = \\\n",
    "                                X[test_idx], y[test_idx], y_orig[test_idx], vol[test_idx]\n",
    "            \n",
    "            X_train_ = X_train_[self._timesteps:]\n",
    "            y_train_ = y_train_[self._timesteps:]\n",
    "            y_train_orig_ = y_train_orig_[self._timesteps:]\n",
    "            vol_train_ = vol_train_[self._timesteps:]\n",
    "            \n",
    "            X_train.append(X_train_)\n",
    "            X_val.append(X_val_)\n",
    "            X_test.append(X_test_)\n",
    "            \n",
    "            y_train.append(y_train_)\n",
    "            y_val.append(y_val_)\n",
    "            y_test.append(y_test_)\n",
    "            \n",
    "            y_train_orig.append(y_train_orig_)\n",
    "            y_val_orig.append(y_val_orig_)\n",
    "            y_test_orig.append(y_test_orig_)\n",
    "            \n",
    "            vol_train.append(vol_train_)\n",
    "            vol_val.append(vol_val_)\n",
    "            vol_test.append(vol_test_)\n",
    "            \n",
    "            self._data[key] = self._data[key].drop(['idx'], axis=1)\n",
    "            \n",
    "        arrays = [X_train, X_val, X_test, y_train, y_val, y_test, y_train_orig, y_val_orig, y_test_orig, \n",
    "                  vol_train, vol_val, vol_test]\n",
    "            \n",
    "        def _to_tensor(x):\n",
    "            x = np.concatenate(x, axis=2)\n",
    "            x = torch.Tensor(x)\n",
    "            return x\n",
    "        \n",
    "        for i in range(len(arrays)):\n",
    "            arrays[i] = _to_tensor(arrays[i])\n",
    "        \n",
    "        \n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, y_train_orig, y_val_orig, y_test_orig, \\\n",
    "                  vol_train, vol_val, vol_test = arrays\n",
    "        \n",
    "        if self._cat_cols:\n",
    "            X_cat = np.zeros((len(train_val_test), self._timesteps, len(self._cat_cols)))\n",
    "            \n",
    "            for i, col in enumerate(self._cat_cols):\n",
    "                for j in range(self._timesteps):\n",
    "                    X_cat[:, j, i] = train_val_test[col].shift(self._timesteps - j - 1)\n",
    "            \n",
    "            X_train_cat, X_val_cat, X_test_cat =\\\n",
    "                torch.Tensor(X_cat[train_idx]), torch.Tensor(X_cat[val_idx]), torch.Tensor(X_cat[test_idx])\n",
    "            \n",
    "            X_train_cat = X_train_cat[self._timesteps:]\n",
    "            \n",
    "        #check alignment by time axis\n",
    "        for i in range(1, len(test_datetimes)):\n",
    "            assert np.all((test_datetimes[i] - test_datetimes[0]) == pd.Timedelta(0))\n",
    "        assert len(X_test) == len(test_datetimes[0]) \n",
    "\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        \n",
    "        if self._encoder_length is None:\n",
    "            \n",
    "            if self._cat_cols:\n",
    "                X_train = torch.cat([X_train, X_train_cat], dim=2)\n",
    "                X_val = torch.cat([X_val, X_val_cat], dim=2)\n",
    "                X_test = torch.cat([X_test, X_test_cat], dim=2)\n",
    "            \n",
    "            cat_info = {}\n",
    "            \n",
    "            train_loader = DataLoader(TensorDataset(X_train, y_train, y_train_orig, vol_train),\n",
    "                                  shuffle=True, batch_size=self._batch_size,\n",
    "                                 worker_init_fn=seed_worker, generator=g)\n",
    "            val_loader = DataLoader(TensorDataset(X_val, y_val, y_val_orig, vol_val),\n",
    "                                    shuffle=False, batch_size=self._batch_size)\n",
    "            test_loader = DataLoader(TensorDataset(X_test, y_test, y_test_orig, vol_test),\n",
    "                                     shuffle=False, batch_size=self._batch_size)\n",
    "        else:\n",
    "            \n",
    "            def _split_encoder_decoder(x, t):\n",
    "                x_enc = x[:, :t, :]\n",
    "                x_dec = x[:, t:, :]\n",
    "\n",
    "                x_enc_length = torch.ones(len(x)).long()\n",
    "                x_enc_length.fill_(x_enc.shape[1])\n",
    "                x_dec_length = torch.ones(len(x)).long()\n",
    "                x_dec_length.fill_(x_dec.shape[1])\n",
    "            \n",
    "                return x_enc, x_dec, x_enc_length, x_dec_length\n",
    "            \n",
    "            \n",
    "            X_train_enc_real, X_train_dec_real, X_train_enc_len, X_train_dec_len =\\\n",
    "                _split_encoder_decoder(X_train, self._encoder_length)\n",
    "            \n",
    "            X_val_enc_real, X_val_dec_real, X_val_enc_len, X_val_dec_len =\\\n",
    "                _split_encoder_decoder(X_val, self._encoder_length)\n",
    "            \n",
    "            X_test_enc_real, X_test_dec_real, X_test_enc_len, X_test_dec_len =\\\n",
    "                _split_encoder_decoder(X_test, self._encoder_length)\n",
    "            \n",
    "            \n",
    "            if not self._cat_cols:\n",
    "                X_train_cat = torch.zeros_like(X_train).long()\n",
    "                X_val_cat = torch.zeros_like(X_val).long()\n",
    "                X_test_cat = torch.zeros_like(X_test).long()\n",
    "            else:\n",
    "                X_train_cat = X_train_cat.long()\n",
    "                X_val_cat = X_val_cat.long()\n",
    "                X_test_cat = X_test_cat.long()\n",
    "            \n",
    "            X_train_enc_cat, X_train_dec_cat, _, _ =\\\n",
    "                _split_encoder_decoder(X_train_cat, self._encoder_length)\n",
    "            \n",
    "            X_val_enc_cat, X_val_dec_cat, _, _ =\\\n",
    "                _split_encoder_decoder(X_val_cat, self._encoder_length)\n",
    "            \n",
    "            X_test_enc_cat, X_test_dec_cat, _, _ =\\\n",
    "                _split_encoder_decoder(X_test_cat, self._encoder_length)\n",
    "            \n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(TensorDataset(X_train_enc_real, X_train_enc_cat,\n",
    "                                                    X_train_dec_real, X_train_dec_cat,\n",
    "                                                    X_train_enc_len, X_train_dec_len,\n",
    "                                                    y_train, y_train_orig, vol_train),\n",
    "                                                    shuffle=True, batch_size=self._batch_size,\n",
    "                                                    worker_init_fn=seed_worker, generator=g)\n",
    "            \n",
    "            val_loader = DataLoader(TensorDataset(X_val_enc_real, X_val_enc_cat,\n",
    "                                                  X_val_dec_real, X_val_dec_cat,\n",
    "                                                  X_val_enc_len, X_val_dec_len,\n",
    "                                                  y_val, y_val_orig, vol_val),\n",
    "                                                  shuffle=False, batch_size=self._batch_size)\n",
    "            \n",
    "            test_loader = DataLoader(TensorDataset(X_test_enc_real, X_test_enc_cat,\n",
    "                                                   X_test_dec_real, X_test_dec_cat,\n",
    "                                                   X_test_enc_len, X_test_dec_len,\n",
    "                                                   y_test, y_test_orig, vol_test),\n",
    "                                                   shuffle=False, batch_size=self._batch_size)\n",
    "            \n",
    "            if self._cat_cols:\n",
    "                cat_info = {i: len(torch.unique(X_train_enc_cat[..., i])) \\\n",
    "                            for i in range(len(self._cat_cols))}\n",
    "            else:\n",
    "                cat_info = {}\n",
    "\n",
    "                \n",
    "        return train_loader, val_loader, test_loader, test_datetimes[0], cat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35e362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter = MultivariateTrainValTestSplitter(features, cols_to_use, datetime_cols, 'target_returns',\n",
    "#                                             'target_returns_nonscaled', 'daily_vol', scaling=scaling,\n",
    "#                                             timesteps=history_size, encoder_length=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3b98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, val_loader, test_loader, test_datetimes, cat_info = splitter.split(date_range[0], val_delta,\n",
    "#                                                                                   test_delta, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df534b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_seed(seed):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f5c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_loss(preds, returns, weights=None):\n",
    "    R = preds*returns\n",
    "\n",
    "    R_sum = torch.mean(R, dim=(1, 0))\n",
    "    R_sum_sq = R_sum**2\n",
    "    R_sq_sum = torch.mean(R**2, dim=(1, 0))\n",
    "    \n",
    "    sharpe = -1*252**0.5*R_sum/torch.sqrt(R_sq_sum - R_sum_sq + 1e-9)\n",
    "    \n",
    "    if weights is None:\n",
    "        sharpe = sharpe * 1/returns.shape[2]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    sharpe = torch.sum(sharpe)\n",
    "    \n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba0b6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_turnover(preds, vol, alpha=1e-4, is_l1=True, target_vol=0.15, C=5):\n",
    "    vol = vol*252**0.5\n",
    "    y = preds/(vol + 1e-12)\n",
    "    y = torch.diff(y, dim=1)\n",
    "    \n",
    "    if is_l1:\n",
    "        y = torch.abs(y)\n",
    "    else:\n",
    "        y = y**2\n",
    "        \n",
    "        \n",
    "    l = alpha*C*target_vol*torch.mean(y)    \n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca84742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_l1(model, alpha=1e-4):\n",
    "    l = 0\n",
    "    for p in model.parameters():\n",
    "        l += torch.mean(torch.abs(p))\n",
    "    \n",
    "    l = alpha*l\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11155c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6782f581c03e4223b39cd1f882e7c7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0596ca8868074c54be7bc7d0151f6426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8100b2e8c01640d7890e62b45b71faa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "Train loss:  -0.95\n",
      "Val loss:  -1.157\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  4.468\n",
      "C:  1 SR:  4.259\n",
      "C:  5 SR:  3.422\n",
      "C:  10 SR:  2.378\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00815c5a69e7455cba01072e27f781cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6edf1b45e2a44449685ac94ff50b0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  1\n",
      "Train loss:  -2.7\n",
      "Val loss:  -0.168\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  -0.65\n",
      "C:  1 SR:  -0.855\n",
      "C:  5 SR:  -1.681\n",
      "C:  10 SR:  -2.712\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e550c93d234858bf1054d084a766a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2066f166600545689ae4845c0c6d04bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  2\n",
      "Train loss:  -4.286\n",
      "Val loss:  -0.331\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  -0.084\n",
      "C:  1 SR:  -0.288\n",
      "C:  5 SR:  -1.109\n",
      "C:  10 SR:  -2.139\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e04ef78ced14a39857bc8c577aba13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046487e23fea4cc7bc2ffee3a99d188b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  3\n",
      "Train loss:  -5.783\n",
      "Val loss:  -0.491\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.599\n",
      "C:  1 SR:  0.395\n",
      "C:  5 SR:  -0.425\n",
      "C:  10 SR:  -1.454\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31857a5a24a54b80b9d35902779b96bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eabeee6c50e4e7e97b5f49d2042c80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  4\n",
      "Train loss:  -6.831\n",
      "Val loss:  -0.552\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.641\n",
      "C:  1 SR:  0.43\n",
      "C:  5 SR:  -0.418\n",
      "C:  10 SR:  -1.48\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c26876413a4b08be6ef27a7fb3a536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2146e06dc64040c4a565edce4758c10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  5\n",
      "Train loss:  -7.341\n",
      "Val loss:  -0.406\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.221\n",
      "C:  1 SR:  0.021\n",
      "C:  5 SR:  -0.784\n",
      "C:  10 SR:  -1.793\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab62fb3ec1248489fc7cb011212fbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c047a0a3c29429c8d03c6383d2fc436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  6\n",
      "Train loss:  -8.031\n",
      "Val loss:  -0.483\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.281\n",
      "C:  1 SR:  0.059\n",
      "C:  5 SR:  -0.833\n",
      "C:  10 SR:  -1.946\n",
      "Epochs till end:  8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483921df212e4be194ee3b24cb9402b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eec43d544674676885877f121315b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  7\n",
      "Train loss:  -8.624\n",
      "Val loss:  -0.608\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.694\n",
      "C:  1 SR:  0.438\n",
      "C:  5 SR:  -0.589\n",
      "C:  10 SR:  -1.87\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337a2449e4f54641bedaf0e305afda71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bace427b03ff46abada0a8ae9a22fb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  8\n",
      "Train loss:  -9.009\n",
      "Val loss:  -0.619\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.714\n",
      "C:  1 SR:  0.442\n",
      "C:  5 SR:  -0.648\n",
      "C:  10 SR:  -2.008\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b309ac83604eae83b48e93d53dc2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f5e81301e246d1b59ac592c4dcfa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  9\n",
      "Train loss:  -9.42\n",
      "Val loss:  -0.602\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.616\n",
      "C:  1 SR:  0.331\n",
      "C:  5 SR:  -0.811\n",
      "C:  10 SR:  -2.234\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33418745db04e59abdc51e16bedb9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fe21e577724f16804b85d6c95cfa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  10\n",
      "Train loss:  -9.812\n",
      "Val loss:  -0.691\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.987\n",
      "C:  1 SR:  0.688\n",
      "C:  5 SR:  -0.511\n",
      "C:  10 SR:  -2.008\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5e07ff83a047d18ca0898f557e14c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d97518325e40fea5bc695ed4f784b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  11\n",
      "Train loss:  -10.113\n",
      "Val loss:  -0.563\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.546\n",
      "C:  1 SR:  0.261\n",
      "C:  5 SR:  -0.882\n",
      "C:  10 SR:  -2.306\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f896f7865d99465597306fec15b1e9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f52fd5999464814a51be02f879ec2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  12\n",
      "Train loss:  -10.379\n",
      "Val loss:  -0.565\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.533\n",
      "C:  1 SR:  0.245\n",
      "C:  5 SR:  -0.906\n",
      "C:  10 SR:  -2.342\n",
      "Epochs till end:  8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15838eb9980b4d6a954b0f9be3760032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ddfdc6a22d4f06bdffaa56b5c2c544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  13\n",
      "Train loss:  -10.624\n",
      "Val loss:  -0.578\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.574\n",
      "C:  1 SR:  0.278\n",
      "C:  5 SR:  -0.905\n",
      "C:  10 SR:  -2.38\n",
      "Epochs till end:  7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f3e11d5984b33ab8edfc873e8487d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7919493b82745c8bae09727c797454b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  14\n",
      "Train loss:  -10.858\n",
      "Val loss:  -0.553\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.443\n",
      "C:  1 SR:  0.152\n",
      "C:  5 SR:  -1.016\n",
      "C:  10 SR:  -2.472\n",
      "Epochs till end:  6\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad9040966194a1f812142abd6667789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a443372f854b6287025e78f6c294e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  15\n",
      "Train loss:  -11.042\n",
      "Val loss:  -0.693\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.903\n",
      "C:  1 SR:  0.598\n",
      "C:  5 SR:  -0.626\n",
      "C:  10 SR:  -2.15\n",
      "Epochs till end:  5\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee475378522a47789b2927094870d803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a6978dec4a42cd9906d1ce288d90ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  16\n",
      "Train loss:  -11.319\n",
      "Val loss:  -0.691\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.92\n",
      "C:  1 SR:  0.602\n",
      "C:  5 SR:  -0.671\n",
      "C:  10 SR:  -2.258\n",
      "Epochs till end:  4\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9049a5ba3ce249d59443546e1e5a029c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efab9e6ad8dc4e10926de607381d1011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  17\n",
      "Train loss:  -11.523\n",
      "Val loss:  -0.702\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.898\n",
      "C:  1 SR:  0.583\n",
      "C:  5 SR:  -0.683\n",
      "C:  10 SR:  -2.263\n",
      "Epochs till end:  3\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53501d7358244c3a6df2f9afbd9acfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf139cf675cd494498e967bd8d71de3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  18\n",
      "Train loss:  -11.753\n",
      "Val loss:  -0.629\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.697\n",
      "C:  1 SR:  0.385\n",
      "C:  5 SR:  -0.864\n",
      "C:  10 SR:  -2.424\n",
      "Epochs till end:  2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5181df984cc41af9e2c02d2d2835263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef597b51ea0c4ed2826efda5a0acf0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  19\n",
      "Train loss:  -11.926\n",
      "Val loss:  -0.697\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.954\n",
      "C:  1 SR:  0.631\n",
      "C:  5 SR:  -0.665\n",
      "C:  10 SR:  -2.285\n",
      "Epochs till end:  1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3297ed5d0784831a7c167594800ff4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35b6b32bbd04d4ba226f0714a4e1dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  20\n",
      "Train loss:  -12.15\n",
      "Val loss:  -0.704\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.914\n",
      "C:  1 SR:  0.589\n",
      "C:  5 SR:  -0.714\n",
      "C:  10 SR:  -2.346\n",
      "Epochs till end:  0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c09d2443b3047fc85d82a011400f9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153854dff95a4959a1ad9b261e102a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dates:  2017-01-01 00:00:00 2018-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fd263b58fd4dceb59510a4efd8359f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0666adc0d94bb19925225459829c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19208b654da34b489dea79611f681f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "Train loss:  -1.106\n",
      "Val loss:  -0.455\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.588\n",
      "C:  1 SR:  0.545\n",
      "C:  5 SR:  0.373\n",
      "C:  10 SR:  0.159\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c32f17583244ea79df7952cb4d5140f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f3872ea7c74ce1a128964e9c63c698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  1\n",
      "Train loss:  -2.861\n",
      "Val loss:  -0.51\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.637\n",
      "C:  1 SR:  0.594\n",
      "C:  5 SR:  0.422\n",
      "C:  10 SR:  0.209\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02894e169264ba8bf91415ee329b3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8aedd0837bd471ea2cfde3d8c289176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  2\n",
      "Train loss:  -4.713\n",
      "Val loss:  -0.698\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.988\n",
      "C:  1 SR:  0.94\n",
      "C:  5 SR:  0.748\n",
      "C:  10 SR:  0.509\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f17ca19fcd3428d8bc37a72c3910038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a55e103268047519e7bab5e1ab7cc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  3\n",
      "Train loss:  -5.962\n",
      "Val loss:  -0.687\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.89\n",
      "C:  1 SR:  0.837\n",
      "C:  5 SR:  0.624\n",
      "C:  10 SR:  0.359\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d1017cb2234bf3a8c57ef0c4f64b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6799dfa235743a6bcefbcbca1ccc869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  4\n",
      "Train loss:  -6.992\n",
      "Val loss:  -0.64\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.821\n",
      "C:  1 SR:  0.755\n",
      "C:  5 SR:  0.492\n",
      "C:  10 SR:  0.164\n",
      "Epochs till end:  8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7382f44de7514029bf2d2b4cb98c554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a483c66438479dbedb73cac79bf76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  5\n",
      "Train loss:  -7.68\n",
      "Val loss:  -0.769\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.057\n",
      "C:  1 SR:  0.988\n",
      "C:  5 SR:  0.711\n",
      "C:  10 SR:  0.366\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1571648b9e4bf5806b0dc4c84fd12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84101aa2d8b4072b9cc25a2d03d7733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  6\n",
      "Train loss:  -8.223\n",
      "Val loss:  -0.724\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  0.935\n",
      "C:  1 SR:  0.859\n",
      "C:  5 SR:  0.555\n",
      "C:  10 SR:  0.176\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d87c792a05948fb88861d6863bc5e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0954db78a7604274a96f135cfaa72791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  7\n",
      "Train loss:  -8.624\n",
      "Val loss:  -0.761\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.008\n",
      "C:  1 SR:  0.928\n",
      "C:  5 SR:  0.606\n",
      "C:  10 SR:  0.204\n",
      "Epochs till end:  8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00828615f5948619e0c36c3ba9e865b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38bee7d1e9a428c911c2a32c2e15f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  8\n",
      "Train loss:  -9.12\n",
      "Val loss:  -0.865\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.203\n",
      "C:  1 SR:  1.111\n",
      "C:  5 SR:  0.743\n",
      "C:  10 SR:  0.284\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee46cce5b0da4c849033991e28110181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa07a33fec024ebebd5656961ed6d18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  9\n",
      "Train loss:  -9.425\n",
      "Val loss:  -0.951\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.303\n",
      "C:  1 SR:  1.202\n",
      "C:  5 SR:  0.8\n",
      "C:  10 SR:  0.298\n",
      "Epochs till end:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc142130d6340419fa41688a5ac86ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0537efede39944fcb3a34597f6914b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  10\n",
      "Train loss:  -9.851\n",
      "Val loss:  -0.886\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.178\n",
      "C:  1 SR:  1.072\n",
      "C:  5 SR:  0.651\n",
      "C:  10 SR:  0.125\n",
      "Epochs till end:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed0b41cbedd48528653a71235d8a96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06f7cc241a0431195641c2e2797525e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  11\n",
      "Train loss:  -10.125\n",
      "Val loss:  -0.869\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.095\n",
      "C:  1 SR:  0.99\n",
      "C:  5 SR:  0.57\n",
      "C:  10 SR:  0.046\n",
      "Epochs till end:  8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4f8014c7bd48a7bc90701b2dac98b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a2ad19943248e19c06a7f89bb920d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  12\n",
      "Train loss:  -10.371\n",
      "Val loss:  -0.877\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.126\n",
      "C:  1 SR:  1.016\n",
      "C:  5 SR:  0.577\n",
      "C:  10 SR:  0.03\n",
      "Epochs till end:  7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552bcb835b01437996df55761b29ce4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc3a84916104ba6b3e9631f2a9c5fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  13\n",
      "Train loss:  -10.613\n",
      "Val loss:  -0.855\n",
      "Validation Sharpe Ratio\n",
      "C:  0 SR:  1.034\n",
      "C:  1 SR:  0.921\n",
      "C:  5 SR:  0.473\n",
      "C:  10 SR:  -0.087\n",
      "Epochs till end:  6\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263ecb57a82145c295aec319b9e6429d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in [42]:\n",
    "    \n",
    "    if not os.path.exists('weights'):\n",
    "        os.mkdir('weights')\n",
    "    if not os.path.exists('results'):\n",
    "        os.mkidr('results')\n",
    "    \n",
    "    test_dts = []\n",
    "    results = {}\n",
    "    splitter = MultivariateTrainValTestSplitter(features, cols_to_use, datetime_cols,\n",
    "                                                'target_returns', 'target_returns_nonscaled',\n",
    "                                                'daily_vol', scaling=scaling, timesteps=history_size,\n",
    "                                                 encoder_length=encoder_length)\n",
    "    for start in date_range:\n",
    "        train_loader, val_loader, test_loader, test_dt, cat_info = splitter.split(start, val_delta,\n",
    "                                                                                  test_delta, seed)\n",
    "        test_dts.append(test_dt)\n",
    "        if len(test_loader) == 0:\n",
    "            continue\n",
    "        \n",
    "        dt = start\n",
    "        results[dt] = {}\n",
    "        \n",
    "        batch_data = next(iter(train_loader))\n",
    "        if model_type != 'tft':\n",
    "            batch_x, batch_y, _, _ = batch_data\n",
    "        else:\n",
    "            batch_x, _, _, _, _, _, batch_y, _, _ = batch_data\n",
    "        \n",
    "        input_dim = batch_x.shape[2]\n",
    "        output_dim = batch_y.shape[2]\n",
    "        timesteps = history_size\n",
    "        \n",
    "        _set_seed(seed)\n",
    "        model = MODEL_MAPPING[model_type](input_dim, output_dim,\n",
    "                                          timesteps, cat_info=cat_info, **model_params).to(device)\n",
    "        \n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        sc = torch.optim.lr_scheduler.StepLR(opt, decay_steps, decay_gamma)\n",
    "\n",
    "        counter = 0\n",
    "        \n",
    "        train_losses = []\n",
    "        train_l1_losses = []\n",
    "        train_turnover_losses = []\n",
    "        val_losses = []\n",
    "        val_turnover_losses = []\n",
    "        best_val_sharpe = np.NINF\n",
    "        \n",
    "        for e in tqdm(range(n_epochs)):\n",
    "            train_loss = 0\n",
    "            train_l1_loss = 0\n",
    "            train_turnover_loss = 0\n",
    "            model.train()\n",
    "            for batch_data in tqdm(train_loader):\n",
    "                for i in range(len(batch_data)):\n",
    "                    batch_data[i] = batch_data[i].to(device)\n",
    "                \n",
    "                if model_type != 'tft':\n",
    "                    batch_x, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                    input_data = [batch_x]\n",
    "                else:\n",
    "                    batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                    batch_enc_len, batch_dec_len, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                    input_data = [batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                                  batch_enc_len, batch_dec_len]\n",
    "                    \n",
    "\n",
    "                opt.zero_grad()\n",
    "\n",
    "                output = model(*input_data)\n",
    "\n",
    "                l = sharpe_loss(output, batch_y)\n",
    "                train_loss += l.item()\n",
    "            \n",
    "                if apply_l1_reg:\n",
    "                    l_l1 = reg_l1(model)\n",
    "                    train_l1_loss += l_l1.item()\n",
    "                    l += l_l1\n",
    "\n",
    "                if apply_turnover_reg:\n",
    "                    l_turnover = reg_turnover(output, batch_vol)\n",
    "                    train_turnover_loss += l_turnover.item()\n",
    "                    l += l_turnover\n",
    "                \n",
    "                l.backward()\n",
    "                opt.step()\n",
    "            \n",
    "            # we do not want learning rate to be too small\n",
    "            if sc.get_last_lr()[0] > 1e-5:\n",
    "                sc.step()\n",
    "            \n",
    "            val_loss = 0\n",
    "            val_turnover_loss = 0\n",
    "            \n",
    "            preds = []\n",
    "            returns = []\n",
    "            vols = []\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_data in tqdm(val_loader):\n",
    "                    for i in range(len(batch_data)):\n",
    "                        batch_data[i] = batch_data[i].to(device)\n",
    "\n",
    "                    if model_type != 'tft':\n",
    "                        batch_x, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                        input_data = [batch_x]\n",
    "                    else:\n",
    "                        batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                        batch_enc_len, batch_dec_len, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                        input_data = [batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                                      batch_enc_len, batch_dec_len]\n",
    "                    \n",
    "                    output = model(*input_data)\n",
    "                    \n",
    "                    l = sharpe_loss(output, batch_y)\n",
    "                    val_loss += l.item()\n",
    "\n",
    "                    if apply_turnover_reg:\n",
    "                        l_turnover = reg_turnover(output, batch_vol)\n",
    "                        val_turnover_loss += l_turnover.item()\n",
    "                    \n",
    "                    # select last timestep as we no longer need for time axis in batch\n",
    "                    returns.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "                    preds.append(output[:, -1, :].detach().cpu().numpy())\n",
    "                    vols.append(batch_vol[:, -1, :].detach().cpu().numpy())\n",
    "                    \n",
    "                    \n",
    "            preds = np.concatenate(preds)\n",
    "            returns = np.concatenate(returns)\n",
    "            vols = np.concatenate(vols)\n",
    "            \n",
    "            #annualized volatility\n",
    "            vols = vols * 252**0.5\n",
    "            # validation turnover\n",
    "            T = target_vol*np.abs(np.diff(preds/(vols+1e-12), prepend=0.0, axis=0))\n",
    "            # validation sharpe ratios with different turnover strength\n",
    "            val_sharpes = {}\n",
    "\n",
    "            for c in basis_points:\n",
    "                captured = returns*preds - 1e-4*c*T\n",
    "                R = np.mean(captured, axis=1)\n",
    "                sharpes = sharpe_ratio(R)\n",
    "                #sharpes = [sharpe_ratio(captured[:, i]) for i in range(captured.shape[1])]\n",
    "                sharpes = np.mean(sharpes)\n",
    "                val_sharpes[c] = sharpes\n",
    "                \n",
    "            # one can use sharpe ratio averaged by all turnover coefficients as validation performance metric\n",
    "            #val_sharpe = np.mean(list(val_sharpes.values()))\n",
    "            \n",
    "            val_sharpe = val_sharpes[0]\n",
    "            \n",
    "            if best_val_sharpe < val_sharpe and e > 0:\n",
    "                best_val_sharpe = val_sharpe\n",
    "                counter = 0\n",
    "                torch.save(model.state_dict(), os.path.join('weights', '{}_seed_{}.pt'.format(model_type, seed)))\n",
    "            \n",
    "            else:\n",
    "                counter += 1\n",
    "            \n",
    "            if counter > early_stopping_rounds:\n",
    "                break\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_l1_loss/= len(train_loader)\n",
    "            train_turnover_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            val_turnover_loss /= len(val_loader)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            train_l1_losses.append(train_l1_loss)\n",
    "            train_turnover_losses.append(train_turnover_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_turnover_losses.append(val_turnover_loss)\n",
    "            \n",
    "            print('Iter: ', e)\n",
    "            print('Train loss: ', round(train_losses[-1], 3))\n",
    "            print('Val loss: ', round(val_losses[-1], 3))\n",
    "            print('Validation Sharpe Ratio')\n",
    "            for key in val_sharpes.keys():\n",
    "                print('C: ', key, 'SR: ', round(val_sharpes[key], 3))\n",
    "            if apply_l1_reg:\n",
    "                print('L1 loss', round(train_l1_losses[-1], 5))\n",
    "            if apply_turnover_reg:\n",
    "                print('Train turnover loss: ', round(train_turnover_losses[-1], 5))\n",
    "                print('Val turnover loss: ', round(val_turnover_losses[-1], 5))\n",
    "            print('Epochs till end: ', early_stopping_rounds - counter)\n",
    "            print()\n",
    "        \n",
    "        print('Validation dates: ', start, start+val_delta)\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.title('Loss evolution')\n",
    "        #plt.plot(train_losses, label='train', marker='o')\n",
    "        plt.plot(val_losses, label='validation', marker='o')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        if apply_l1_reg:\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.title('L1 regularization loss evolution')\n",
    "            plt.plot(train_l1_losses, label='train', marker='o')\n",
    "            plt.ylabel('L1 Loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        if apply_turnover_reg:\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.title('Turnover loss evolution')\n",
    "            plt.plot(train_turnover_losses, label='train', marker='o')\n",
    "            plt.plot(val_turnover_losses, label='validation', marker='o')\n",
    "            plt.ylabel('Turnover loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        model.load_state_dict(torch.load(os.path.join('weights', '{}_seed_{}.pt'.format(model_type, seed))))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        val_preds = []\n",
    "        val_returns = []\n",
    "        val_returns_orig = []\n",
    "        val_vols = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data in val_loader:\n",
    "                for i in range(len(batch_data)):\n",
    "                    batch_data[i] = batch_data[i].to(device)\n",
    "                \n",
    "                if model_type != 'tft':\n",
    "                    batch_x, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                    input_data = [batch_x]\n",
    "                else:\n",
    "                    batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                    batch_enc_len, batch_dec_len, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                    input_data = [batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                                  batch_enc_len, batch_dec_len]\n",
    "\n",
    "                output = model(*input_data)\n",
    "\n",
    "\n",
    "                # select last timestep as we no longer need for time axis in batch\n",
    "                val_returns.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "                val_returns_orig.append(batch_y_orig[:, -1, :].detach().cpu().numpy())\n",
    "                val_preds.append(output[:, -1, :].detach().cpu().numpy())\n",
    "                val_vols.append(batch_vol[:, -1, :].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_returns = np.concatenate(val_returns)\n",
    "        val_returns_orig = np.concatenate(val_returns_orig)\n",
    "        val_vols = np.concatenate(val_vols)\n",
    "        \n",
    "        test_preds = []\n",
    "        test_returns = []\n",
    "        test_returns_orig = []\n",
    "        test_vols = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data in test_loader:\n",
    "                for i in range(len(batch_data)):\n",
    "                    batch_data[i] = batch_data[i].to(device)\n",
    "                \n",
    "                if model_type != 'tft':\n",
    "                    batch_x, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                    input_data = [batch_x]\n",
    "                else:\n",
    "                    batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                    batch_enc_len, batch_dec_len, batch_y, batch_y_orig, batch_vol = batch_data\n",
    "                    input_data = [batch_x_enc_real, batch_x_enc_cat, batch_x_dec_real, batch_x_dec_cat, \\\n",
    "                                  batch_enc_len, batch_dec_len]\n",
    "\n",
    "                output = model(*input_data)\n",
    "\n",
    "\n",
    "                # select last timestep as we no longer need for time axis in batch\n",
    "                test_returns.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "                test_returns_orig.append(batch_y_orig[:, -1, :].detach().cpu().numpy())\n",
    "                test_preds.append(output[:, -1, :].detach().cpu().numpy())\n",
    "                test_vols.append(batch_vol[:, -1, :].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        test_preds = np.concatenate(test_preds)\n",
    "        test_returns = np.concatenate(test_returns)\n",
    "        test_returns_orig = np.concatenate(test_returns_orig)\n",
    "        test_vols = np.concatenate(test_vols)\n",
    "\n",
    "        results[dt]['val'] = {}\n",
    "        results[dt]['test'] = {}\n",
    "        results[dt]['test_dt'] = test_dt\n",
    "        \n",
    "        results[dt]['val']['preds'] = val_preds\n",
    "        results[dt]['val']['returns'] = val_returns\n",
    "        results[dt]['val']['returns_orig'] = val_returns_orig\n",
    "        results[dt]['val']['vols'] = val_vols\n",
    "        \n",
    "        results[dt]['test']['preds'] = test_preds\n",
    "        results[dt]['test']['returns'] = test_returns\n",
    "        results[dt]['test']['returns_orig'] = test_returns_orig\n",
    "        results[dt]['test']['vols'] = test_vols\n",
    "        \n",
    "        \n",
    "    with open(os.path.join('results', '{}_seed_{}_2.pickle'.format(model_type, seed)), 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(batch_x_enc_cat[:, :, i].max(), batch_x_dec_cat[:, :, i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0467179",
   "metadata": {},
   "outputs": [],
   "source": [
    "440*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c84a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "captured.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6940487",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK TURNOVER CALCULATION IN PAPER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9b11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "732397d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('results', '{}_seed_{}.pickle'.format(model_type, seed)), 'rb') as f:\n",
    "    s = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b67ac6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([Timestamp('2017-01-01 00:00:00', freq='365D'), Timestamp('2018-01-01 00:00:00', freq='365D'), Timestamp('2019-01-01 00:00:00', freq='365D'), Timestamp('2020-01-01 00:00:00', freq='365D'), Timestamp('2020-12-31 00:00:00', freq='365D'), Timestamp('2021-12-31 00:00:00', freq='365D')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc1a2bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Timestamp('2017-01-01 00:00:00', freq='365D'): {'val': {'preds': array([[-0.06719825, -0.12165906, -0.15836045, ..., -0.02192476,\n",
       "           -0.05855001, -0.04660154],\n",
       "          [-0.05941394, -0.09929574, -0.16683619, ..., -0.0629783 ,\n",
       "           -0.06911193, -0.05740706],\n",
       "          [-0.03437181, -0.10851533, -0.13773099, ..., -0.0302827 ,\n",
       "           -0.07600641, -0.05329055],\n",
       "          ...,\n",
       "          [-0.06244482, -0.08418113,  0.01842139, ..., -0.07675992,\n",
       "           -0.1257724 ,  0.00476152],\n",
       "          [-0.06811493, -0.07323923,  0.00766079, ..., -0.12835382,\n",
       "           -0.1904522 , -0.03424367],\n",
       "          [-0.02420451, -0.09484015,  0.01929842, ..., -0.08453773,\n",
       "           -0.18312718, -0.03283702]], dtype=float32),\n",
       "   'returns': array([[ 0.01218061, -0.0002563 ,  0.00401444, ...,  0.00114788,\n",
       "            0.00839684,  0.00594892],\n",
       "          [ 0.00948089,  0.00570152, -0.01789113, ...,  0.00440326,\n",
       "            0.        , -0.00164429],\n",
       "          [-0.0004819 ,  0.01330482,  0.01787224, ..., -0.00065294,\n",
       "            0.0212993 ,  0.00809375],\n",
       "          ...,\n",
       "          [ 0.00047336, -0.00399269,  0.003346  , ...,  0.00703658,\n",
       "            0.00839736,  0.00627688],\n",
       "          [-0.00064111, -0.00243449, -0.00644968, ..., -0.00137302,\n",
       "            0.        , -0.00111706],\n",
       "          [ 0.00807626,  0.01923834,  0.00281476, ..., -0.02026302,\n",
       "           -0.01373077, -0.01116215]], dtype=float32),\n",
       "   'returns_orig': array([[ 0.01218061, -0.0002563 ,  0.00401444, ...,  0.00114788,\n",
       "            0.00839684,  0.00594892],\n",
       "          [ 0.00948089,  0.00570152, -0.01789113, ...,  0.00440326,\n",
       "            0.        , -0.00164429],\n",
       "          [-0.0004819 ,  0.01330482,  0.01787224, ..., -0.00065294,\n",
       "            0.0212993 ,  0.00809375],\n",
       "          ...,\n",
       "          [ 0.00047336, -0.00399269,  0.003346  , ...,  0.00703658,\n",
       "            0.00839736,  0.00627688],\n",
       "          [-0.00064111, -0.00243449, -0.00644968, ..., -0.00137302,\n",
       "            0.        , -0.00111706],\n",
       "          [ 0.00807626,  0.01923834,  0.00281476, ..., -0.02026302,\n",
       "           -0.01373077, -0.01116215]], dtype=float32),\n",
       "   'vols': array([[0.015244  , 0.01095149, 0.01201427, ..., 0.01180266, 0.01006786,\n",
       "           0.01366457],\n",
       "          [0.01547271, 0.01077143, 0.01184592, ..., 0.01160879, 0.00999579,\n",
       "           0.01352119],\n",
       "          [0.01550223, 0.01064841, 0.01235926, ..., 0.01145054, 0.00983458,\n",
       "           0.01330805],\n",
       "          ...,\n",
       "          [0.01891026, 0.00948685, 0.01533236, ..., 0.00751706, 0.00839446,\n",
       "           0.01270238],\n",
       "          [0.01859819, 0.0093732 , 0.01510374, ..., 0.00747508, 0.00838829,\n",
       "           0.01263919],\n",
       "          [0.01829264, 0.00923667, 0.01498667, ..., 0.00735268, 0.0082502 ,\n",
       "           0.01243048]], dtype=float32)},\n",
       "  'test': {'preds': array([[-0.09892748, -0.07054201, -0.0171364 , ..., -0.07107146,\n",
       "           -0.10132537, -0.00384185],\n",
       "          [-0.10321162, -0.06260202, -0.03420386, ..., -0.08321393,\n",
       "           -0.14410423, -0.0021268 ],\n",
       "          [-0.06604791, -0.09897167, -0.01801506, ..., -0.15636295,\n",
       "           -0.16267838, -0.05443924],\n",
       "          ...,\n",
       "          [ 0.24660331,  0.3311791 ,  0.33310628, ...,  0.14779516,\n",
       "            0.1463984 ,  0.15760243],\n",
       "          [ 0.3157344 ,  0.37430406,  0.40652078, ...,  0.16231772,\n",
       "            0.20602565,  0.21315564],\n",
       "          [ 0.31562153,  0.40012047,  0.41602564, ...,  0.19718215,\n",
       "            0.21379524,  0.23410958]], dtype=float32),\n",
       "   'returns': array([[ 8.07129219e-03,  1.67111997e-02, -1.54939769e-02, ...,\n",
       "           -1.02830790e-02, -2.41729058e-03,  2.01177690e-02],\n",
       "          [-5.19515201e-03,  3.70763568e-03,  1.29176518e-02, ...,\n",
       "           -1.44671435e-02,  1.23086304e-03, -4.73698601e-03],\n",
       "          [ 1.39498245e-02,  1.28601603e-02,  6.08591305e-04, ...,\n",
       "           -2.54665618e-03, -4.99653770e-03,  6.91830507e-03],\n",
       "          ...,\n",
       "          [-1.56151445e-03, -2.46804464e-03,  4.40857286e-04, ...,\n",
       "           -2.98859458e-03, -2.41003628e-03,  9.11503471e-03],\n",
       "          [-1.52931979e-03, -6.97419397e-04,  4.47372440e-03, ...,\n",
       "            9.83745631e-05,  6.27485616e-03,  5.68962423e-03],\n",
       "          [ 3.12548364e-03,  4.01403382e-03, -8.72983597e-03, ...,\n",
       "           -1.79837253e-02, -6.28433656e-03, -8.84560775e-03]], dtype=float32),\n",
       "   'returns_orig': array([[ 8.07129219e-03,  1.67111997e-02, -1.54939769e-02, ...,\n",
       "           -1.02830790e-02, -2.41729058e-03,  2.01177690e-02],\n",
       "          [-5.19515201e-03,  3.70763568e-03,  1.29176518e-02, ...,\n",
       "           -1.44671435e-02,  1.23086304e-03, -4.73698601e-03],\n",
       "          [ 1.39498245e-02,  1.28601603e-02,  6.08591305e-04, ...,\n",
       "           -2.54665618e-03, -4.99653770e-03,  6.91830507e-03],\n",
       "          ...,\n",
       "          [-1.56151445e-03, -2.46804464e-03,  4.40857286e-04, ...,\n",
       "           -2.98859458e-03, -2.41003628e-03,  9.11503471e-03],\n",
       "          [-1.52931979e-03, -6.97419397e-04,  4.47372440e-03, ...,\n",
       "            9.83745631e-05,  6.27485616e-03,  5.68962423e-03],\n",
       "          [ 3.12548364e-03,  4.01403382e-03, -8.72983597e-03, ...,\n",
       "           -1.79837253e-02, -6.28433656e-03, -8.84560775e-03]], dtype=float32),\n",
       "   'vols': array([[0.0182039 , 0.00964689, 0.01475696, ..., 0.00774092, 0.008371  ,\n",
       "           0.01243893],\n",
       "          [0.01810161, 0.00989974, 0.01517756, ..., 0.00773232, 0.00823565,\n",
       "           0.01328138],\n",
       "          [0.01791362, 0.00974307, 0.01539669, ..., 0.00784368, 0.00810757,\n",
       "           0.01309634],\n",
       "          ...,\n",
       "          [0.03087457, 0.02261738, 0.02101095, ..., 0.01306099, 0.0125613 ,\n",
       "           0.01420471],\n",
       "          [0.03036422, 0.02226405, 0.02067634, ..., 0.01286688, 0.01236966,\n",
       "           0.01424371],\n",
       "          [0.02986235, 0.0218966 , 0.02046228, ..., 0.01265426, 0.01225037,\n",
       "           0.01411935]], dtype=float32)},\n",
       "  'test_dt': DatetimeIndex(['2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05',\n",
       "                 '2018-01-08', '2018-01-09', '2018-01-10', '2018-01-11',\n",
       "                 '2018-01-12', '2018-01-16',\n",
       "                 ...\n",
       "                 '2018-12-17', '2018-12-18', '2018-12-19', '2018-12-20',\n",
       "                 '2018-12-21', '2018-12-24', '2018-12-26', '2018-12-27',\n",
       "                 '2018-12-28', '2018-12-31'],\n",
       "                dtype='datetime64[ns]', name='Date', length=251, freq=None)},\n",
       " Timestamp('2018-01-01 00:00:00', freq='365D'): {'val': {'preds': array([[-0.0246461 , -0.04322935, -0.05006292, ...,  0.01752461,\n",
       "            0.02370057,  0.0391795 ],\n",
       "          [ 0.00560419, -0.02902942, -0.04730371, ...,  0.04762952,\n",
       "           -0.01021515,  0.03879433],\n",
       "          [-0.00439514, -0.07620551, -0.03911961, ..., -0.00877339,\n",
       "            0.02407662,  0.0069331 ],\n",
       "          ...,\n",
       "          [ 0.20212823,  0.23696005,  0.2937069 , ...,  0.18512583,\n",
       "            0.14086103,  0.207083  ],\n",
       "          [ 0.28329137,  0.3030404 ,  0.3727332 , ...,  0.21299003,\n",
       "            0.19521624,  0.25293636],\n",
       "          [ 0.28434682,  0.32459888,  0.3643108 , ...,  0.23118176,\n",
       "            0.21059047,  0.26786134]], dtype=float32),\n",
       "   'returns': array([[ 8.07129219e-03,  1.67111997e-02, -1.54939769e-02, ...,\n",
       "           -1.02830790e-02, -2.41729058e-03,  2.01177690e-02],\n",
       "          [-5.19515201e-03,  3.70763568e-03,  1.29176518e-02, ...,\n",
       "           -1.44671435e-02,  1.23086304e-03, -4.73698601e-03],\n",
       "          [ 1.39498245e-02,  1.28601603e-02,  6.08591305e-04, ...,\n",
       "           -2.54665618e-03, -4.99653770e-03,  6.91830507e-03],\n",
       "          ...,\n",
       "          [-1.56151445e-03, -2.46804464e-03,  4.40857286e-04, ...,\n",
       "           -2.98859458e-03, -2.41003628e-03,  9.11503471e-03],\n",
       "          [-1.52931979e-03, -6.97419397e-04,  4.47372440e-03, ...,\n",
       "            9.83745631e-05,  6.27485616e-03,  5.68962423e-03],\n",
       "          [ 3.12548364e-03,  4.01403382e-03, -8.72983597e-03, ...,\n",
       "           -1.79837253e-02, -6.28433656e-03, -8.84560775e-03]], dtype=float32),\n",
       "   'returns_orig': array([[ 8.07129219e-03,  1.67111997e-02, -1.54939769e-02, ...,\n",
       "           -1.02830790e-02, -2.41729058e-03,  2.01177690e-02],\n",
       "          [-5.19515201e-03,  3.70763568e-03,  1.29176518e-02, ...,\n",
       "           -1.44671435e-02,  1.23086304e-03, -4.73698601e-03],\n",
       "          [ 1.39498245e-02,  1.28601603e-02,  6.08591305e-04, ...,\n",
       "           -2.54665618e-03, -4.99653770e-03,  6.91830507e-03],\n",
       "          ...,\n",
       "          [-1.56151445e-03, -2.46804464e-03,  4.40857286e-04, ...,\n",
       "           -2.98859458e-03, -2.41003628e-03,  9.11503471e-03],\n",
       "          [-1.52931979e-03, -6.97419397e-04,  4.47372440e-03, ...,\n",
       "            9.83745631e-05,  6.27485616e-03,  5.68962423e-03],\n",
       "          [ 3.12548364e-03,  4.01403382e-03, -8.72983597e-03, ...,\n",
       "           -1.79837253e-02, -6.28433656e-03, -8.84560775e-03]], dtype=float32),\n",
       "   'vols': array([[0.0182039 , 0.00964689, 0.01475696, ..., 0.00774092, 0.008371  ,\n",
       "           0.01243893],\n",
       "          [0.01810161, 0.00989974, 0.01517756, ..., 0.00773232, 0.00823565,\n",
       "           0.01328138],\n",
       "          [0.01791362, 0.00974307, 0.01539669, ..., 0.00784368, 0.00810757,\n",
       "           0.01309634],\n",
       "          ...,\n",
       "          [0.03087457, 0.02261738, 0.02101095, ..., 0.01306099, 0.0125613 ,\n",
       "           0.01420471],\n",
       "          [0.03036422, 0.02226405, 0.02067634, ..., 0.01286688, 0.01236966,\n",
       "           0.01424371],\n",
       "          [0.02986235, 0.0218966 , 0.02046228, ..., 0.01265426, 0.01225037,\n",
       "           0.01411935]], dtype=float32)},\n",
       "  'test': {'preds': array([[ 0.30602705,  0.34290096,  0.38726997, ...,  0.21026225,\n",
       "            0.2289791 ,  0.24688204],\n",
       "          [ 0.20802137,  0.2661282 ,  0.3418625 , ...,  0.17664957,\n",
       "            0.16133673,  0.18415229],\n",
       "          [ 0.15092854,  0.2557972 ,  0.28085858, ...,  0.19593167,\n",
       "            0.16356911,  0.23571588],\n",
       "          ...,\n",
       "          [-0.02734442,  0.00190104,  0.01454677, ...,  0.1547609 ,\n",
       "            0.11782724,  0.03473702],\n",
       "          [ 0.01321144,  0.04313126,  0.04729309, ...,  0.16597025,\n",
       "            0.17047305,  0.07067642],\n",
       "          [-0.08424895, -0.02462488, -0.00104221, ...,  0.11425363,\n",
       "            0.09170776, -0.01488556]], dtype=float32),\n",
       "   'returns': array([[-0.01137642, -0.01210969,  0.00367266, ..., -0.00167197,\n",
       "            0.00444534,  0.00308458],\n",
       "          [ 0.012769  ,  0.02222366,  0.0076051 , ...,  0.00671535,\n",
       "            0.01455635,  0.02039259],\n",
       "          [ 0.00882962, -0.00080394,  0.01159194, ..., -0.00409881,\n",
       "            0.0029632 , -0.00011615],\n",
       "          ...,\n",
       "          [-0.00338592, -0.01109709,  0.00076657, ..., -0.0020882 ,\n",
       "            0.        ,  0.00127782],\n",
       "          [ 0.00600131, -0.00023757,  0.00077881, ...,  0.00636859,\n",
       "            0.00884736,  0.00309912],\n",
       "          [-0.00858864,  0.0221104 , -0.01542972, ..., -0.01401676,\n",
       "           -0.00778465, -0.01723975]], dtype=float32),\n",
       "   'returns_orig': array([[-0.01137642, -0.01210969,  0.00367266, ..., -0.00167197,\n",
       "            0.00444534,  0.00308458],\n",
       "          [ 0.012769  ,  0.02222366,  0.0076051 , ...,  0.00671535,\n",
       "            0.01455635,  0.02039259],\n",
       "          [ 0.00882962, -0.00080394,  0.01159194, ..., -0.00409881,\n",
       "            0.0029632 , -0.00011615],\n",
       "          ...,\n",
       "          [-0.00338592, -0.01109709,  0.00076657, ..., -0.0020882 ,\n",
       "            0.        ,  0.00127782],\n",
       "          [ 0.00600131, -0.00023757,  0.00077881, ...,  0.00636859,\n",
       "            0.00884736,  0.00309912],\n",
       "          [-0.00858864,  0.0221104 , -0.01542972, ..., -0.01401676,\n",
       "           -0.00778465, -0.01723975]], dtype=float32),\n",
       "   'vols': array([[0.02949351, 0.02161074, 0.02033839, ..., 0.01316981, 0.01214633,\n",
       "           0.01405979],\n",
       "          [0.02952829, 0.02180913, 0.02009859, ..., 0.01295473, 0.01198704,\n",
       "           0.01386842],\n",
       "          [0.03017422, 0.0234397 , 0.02005443, ..., 0.01286987, 0.01222969,\n",
       "           0.01473714],\n",
       "          ...,\n",
       "          [0.01461589, 0.00938472, 0.0106881 , ..., 0.00768737, 0.01452787,\n",
       "           0.00882488],\n",
       "          [0.01444009, 0.00949958, 0.01051215, ..., 0.00757417, 0.01428793,\n",
       "           0.00867915],\n",
       "          [0.0142568 , 0.00934559, 0.01033908, ..., 0.00748956, 0.01424351,\n",
       "           0.00853927]], dtype=float32)},\n",
       "  'test_dt': DatetimeIndex(['2019-01-02', '2019-01-03', '2019-01-04', '2019-01-07',\n",
       "                 '2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11',\n",
       "                 '2019-01-14', '2019-01-15',\n",
       "                 ...\n",
       "                 '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
       "                 '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27',\n",
       "                 '2019-12-30', '2019-12-31'],\n",
       "                dtype='datetime64[ns]', name='Date', length=252, freq=None)},\n",
       " Timestamp('2019-01-01 00:00:00', freq='365D'): {'val': {'preds': array([[ 0.03747168,  0.04574095,  0.19600889, ...,  0.08112026,\n",
       "            0.16162302,  0.08379796],\n",
       "          [ 0.02183307,  0.01119745,  0.14323507, ...,  0.02505086,\n",
       "            0.09686021,  0.01498727],\n",
       "          [ 0.03072332,  0.05354369,  0.13909392, ...,  0.11882512,\n",
       "            0.19607577,  0.07733998],\n",
       "          ...,\n",
       "          [-0.12120389, -0.1129458 , -0.14072824, ...,  0.03001384,\n",
       "           -0.02837443, -0.06715908],\n",
       "          [-0.12376633, -0.09839089, -0.11586335, ...,  0.02407867,\n",
       "            0.00743663, -0.06352609],\n",
       "          [-0.18077765, -0.15924439, -0.17237705, ..., -0.02480626,\n",
       "           -0.05163972, -0.12330949]], dtype=float32),\n",
       "   'returns': array([[-0.01137642, -0.01210969,  0.00367266, ..., -0.00167197,\n",
       "            0.00444534,  0.00308458],\n",
       "          [ 0.012769  ,  0.02222366,  0.0076051 , ...,  0.00671535,\n",
       "            0.01455635,  0.02039259],\n",
       "          [ 0.00882962, -0.00080394,  0.01159194, ..., -0.00409881,\n",
       "            0.0029632 , -0.00011615],\n",
       "          ...,\n",
       "          [-0.00338592, -0.01109709,  0.00076657, ..., -0.0020882 ,\n",
       "            0.        ,  0.00127782],\n",
       "          [ 0.00600131, -0.00023757,  0.00077881, ...,  0.00636859,\n",
       "            0.00884736,  0.00309912],\n",
       "          [-0.00858864,  0.0221104 , -0.01542972, ..., -0.01401676,\n",
       "           -0.00778465, -0.01723975]], dtype=float32),\n",
       "   'returns_orig': array([[-0.01137642, -0.01210969,  0.00367266, ..., -0.00167197,\n",
       "            0.00444534,  0.00308458],\n",
       "          [ 0.012769  ,  0.02222366,  0.0076051 , ...,  0.00671535,\n",
       "            0.01455635,  0.02039259],\n",
       "          [ 0.00882962, -0.00080394,  0.01159194, ..., -0.00409881,\n",
       "            0.0029632 , -0.00011615],\n",
       "          ...,\n",
       "          [-0.00338592, -0.01109709,  0.00076657, ..., -0.0020882 ,\n",
       "            0.        ,  0.00127782],\n",
       "          [ 0.00600131, -0.00023757,  0.00077881, ...,  0.00636859,\n",
       "            0.00884736,  0.00309912],\n",
       "          [-0.00858864,  0.0221104 , -0.01542972, ..., -0.01401676,\n",
       "           -0.00778465, -0.01723975]], dtype=float32),\n",
       "   'vols': array([[0.02949351, 0.02161074, 0.02033839, ..., 0.01316981, 0.01214633,\n",
       "           0.01405979],\n",
       "          [0.02952829, 0.02180913, 0.02009859, ..., 0.01295473, 0.01198704,\n",
       "           0.01386842],\n",
       "          [0.03017422, 0.0234397 , 0.02005443, ..., 0.01286987, 0.01222969,\n",
       "           0.01473714],\n",
       "          ...,\n",
       "          [0.01461589, 0.00938472, 0.0106881 , ..., 0.00768737, 0.01452787,\n",
       "           0.00882488],\n",
       "          [0.01444009, 0.00949958, 0.01051215, ..., 0.00757417, 0.01428793,\n",
       "           0.00867915],\n",
       "          [0.0142568 , 0.00934559, 0.01033908, ..., 0.00748956, 0.01424351,\n",
       "           0.00853927]], dtype=float32)},\n",
       "  'test': {'preds': array([[-0.19337958, -0.1549974 , -0.12993233, ...,  0.03027846,\n",
       "           -0.02155952, -0.06468621],\n",
       "          [-0.17484249, -0.14807126, -0.10531022, ..., -0.0200911 ,\n",
       "           -0.01775605, -0.09767223],\n",
       "          [-0.1344852 , -0.12651958, -0.08342709, ..., -0.0021678 ,\n",
       "           -0.04398835, -0.08534268],\n",
       "          ...,\n",
       "          [-0.09213629, -0.01962126, -0.09813345, ..., -0.08561151,\n",
       "           -0.0219491 , -0.04390977],\n",
       "          [-0.14612906, -0.05373537, -0.14447112, ..., -0.1032003 ,\n",
       "           -0.03430653, -0.07761359],\n",
       "          [-0.16167514, -0.04916032, -0.1856483 , ..., -0.16509482,\n",
       "           -0.0878897 , -0.12049547]], dtype=float32),\n",
       "   'returns': array([[ 0.00022544, -0.00498171,  0.00077832, ..., -0.00131733,\n",
       "           -0.00395371, -0.00963758],\n",
       "          [ 0.01225958,  0.02559969,  0.00790743, ...,  0.00415358,\n",
       "           -0.00100786,  0.00883225],\n",
       "          [ 0.00671447, -0.0017093 ,  0.00197393, ...,  0.00027088,\n",
       "            0.00307786, -0.000851  ],\n",
       "          ...,\n",
       "          [ 0.00137088, -0.00729814, -0.00387923, ...,  0.00311491,\n",
       "            0.00262034, -0.00256394],\n",
       "          [ 0.0084098 ,  0.00565526,  0.00107976, ...,  0.01677175,\n",
       "            0.00484958,  0.00729553],\n",
       "          [-0.01945237, -0.0091695 , -0.00693552, ..., -0.01553514,\n",
       "           -0.00662461, -0.01647056]], dtype=float32),\n",
       "   'returns_orig': array([[ 0.00022544, -0.00498171,  0.00077832, ..., -0.00131733,\n",
       "           -0.00395371, -0.00963758],\n",
       "          [ 0.01225958,  0.02559969,  0.00790743, ...,  0.00415358,\n",
       "           -0.00100786,  0.00883225],\n",
       "          [ 0.00671447, -0.0017093 ,  0.00197393, ...,  0.00027088,\n",
       "            0.00307786, -0.000851  ],\n",
       "          ...,\n",
       "          [ 0.00137088, -0.00729814, -0.00387923, ...,  0.00311491,\n",
       "            0.00262034, -0.00256394],\n",
       "          [ 0.0084098 ,  0.00565526,  0.00107976, ...,  0.01677175,\n",
       "            0.00484958,  0.00729553],\n",
       "          [-0.01945237, -0.0091695 , -0.00693552, ..., -0.01553514,\n",
       "           -0.00662461, -0.01647056]], dtype=float32),\n",
       "   'vols': array([[0.01429012, 0.00992261, 0.0106913 , ..., 0.00767556, 0.01418868,\n",
       "           0.00894161],\n",
       "          [0.0140567 , 0.00983832, 0.01051457, ..., 0.00755406, 0.01400076,\n",
       "           0.00897798],\n",
       "          [0.014134  , 0.01067815, 0.01043741, ..., 0.00744687, 0.01377273,\n",
       "           0.00893908],\n",
       "          ...,\n",
       "          [0.01584131, 0.01584383, 0.02263004, ..., 0.0123315 , 0.02031598,\n",
       "           0.01662038],\n",
       "          [0.01558148, 0.01577274, 0.02238112, ..., 0.01216495, 0.02001151,\n",
       "           0.01636748],\n",
       "          [0.0154333 , 0.01558699, 0.02201173, ..., 0.01263661, 0.01977374,\n",
       "           0.01625504]], dtype=float32)},\n",
       "  'test_dt': DatetimeIndex(['2020-01-02', '2020-01-03', '2020-01-06', '2020-01-07',\n",
       "                 '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-13',\n",
       "                 '2020-01-14', '2020-01-15',\n",
       "                 ...\n",
       "                 '2020-12-17', '2020-12-18', '2020-12-21', '2020-12-22',\n",
       "                 '2020-12-23', '2020-12-24', '2020-12-28', '2020-12-29',\n",
       "                 '2020-12-30', '2020-12-31'],\n",
       "                dtype='datetime64[ns]', name='Date', length=253, freq=None)},\n",
       " Timestamp('2020-01-01 00:00:00', freq='365D'): {'val': {'preds': array([[-0.14386107, -0.11274293, -0.12024456, ...,  0.05426339,\n",
       "            0.0185043 ,  0.0227862 ],\n",
       "          [-0.04611866, -0.04317437, -0.05780772, ...,  0.02199806,\n",
       "            0.04841285,  0.01014375],\n",
       "          [-0.04984561,  0.00677438, -0.06657346, ...,  0.00182065,\n",
       "           -0.0052852 , -0.03309382],\n",
       "          ...,\n",
       "          [-0.08750135, -0.04014377, -0.11292624, ..., -0.03933037,\n",
       "           -0.04736267, -0.00565622],\n",
       "          [-0.17106664, -0.10870457, -0.16524148, ..., -0.05243099,\n",
       "           -0.07864016, -0.0253035 ],\n",
       "          [-0.1919143 , -0.11687628, -0.21312952, ..., -0.15858959,\n",
       "           -0.16386092, -0.10173962]], dtype=float32),\n",
       "   'returns': array([[ 0.00022544, -0.00498171,  0.00077832, ..., -0.00131733,\n",
       "           -0.00395371, -0.00963758],\n",
       "          [ 0.01225958,  0.02559969,  0.00790743, ...,  0.00415358,\n",
       "           -0.00100786,  0.00883225],\n",
       "          [ 0.00671447, -0.0017093 ,  0.00197393, ...,  0.00027088,\n",
       "            0.00307786, -0.000851  ],\n",
       "          ...,\n",
       "          [ 0.00137088, -0.00729814, -0.00387923, ...,  0.00311491,\n",
       "            0.00262034, -0.00256394],\n",
       "          [ 0.0084098 ,  0.00565526,  0.00107976, ...,  0.01677175,\n",
       "            0.00484958,  0.00729553],\n",
       "          [-0.01945237, -0.0091695 , -0.00693552, ..., -0.01553514,\n",
       "           -0.00662461, -0.01647056]], dtype=float32),\n",
       "   'returns_orig': array([[ 0.00022544, -0.00498171,  0.00077832, ..., -0.00131733,\n",
       "           -0.00395371, -0.00963758],\n",
       "          [ 0.01225958,  0.02559969,  0.00790743, ...,  0.00415358,\n",
       "           -0.00100786,  0.00883225],\n",
       "          [ 0.00671447, -0.0017093 ,  0.00197393, ...,  0.00027088,\n",
       "            0.00307786, -0.000851  ],\n",
       "          ...,\n",
       "          [ 0.00137088, -0.00729814, -0.00387923, ...,  0.00311491,\n",
       "            0.00262034, -0.00256394],\n",
       "          [ 0.0084098 ,  0.00565526,  0.00107976, ...,  0.01677175,\n",
       "            0.00484958,  0.00729553],\n",
       "          [-0.01945237, -0.0091695 , -0.00693552, ..., -0.01553514,\n",
       "           -0.00662461, -0.01647056]], dtype=float32),\n",
       "   'vols': array([[0.01429012, 0.00992261, 0.0106913 , ..., 0.00767556, 0.01418868,\n",
       "           0.00894161],\n",
       "          [0.0140567 , 0.00983832, 0.01051457, ..., 0.00755406, 0.01400076,\n",
       "           0.00897798],\n",
       "          [0.014134  , 0.01067815, 0.01043741, ..., 0.00744687, 0.01377273,\n",
       "           0.00893908],\n",
       "          ...,\n",
       "          [0.01584131, 0.01584383, 0.02263004, ..., 0.0123315 , 0.02031598,\n",
       "           0.01662038],\n",
       "          [0.01558148, 0.01577274, 0.02238112, ..., 0.01216495, 0.02001151,\n",
       "           0.01636748],\n",
       "          [0.0154333 , 0.01558699, 0.02201173, ..., 0.01263661, 0.01977374,\n",
       "           0.01625504]], dtype=float32)},\n",
       "  'test': {'preds': array([[ 0.02163399, -0.01439518,  0.00291356, ..., -0.02367767,\n",
       "            0.00108686, -0.0245755 ],\n",
       "          [-0.14076759, -0.05827734, -0.14256114, ...,  0.0254574 ,\n",
       "            0.02598941,  0.01891221],\n",
       "          [-0.30633608, -0.22510168, -0.32343596, ..., -0.24401361,\n",
       "           -0.15254317, -0.14465639],\n",
       "          ...,\n",
       "          [-0.20190468, -0.09797809, -0.12096839, ...,  0.03977547,\n",
       "           -0.05506571,  0.05448133],\n",
       "          [-0.14721754, -0.10112505, -0.08096331, ...,  0.04973738,\n",
       "           -0.05591914,  0.05708442],\n",
       "          [-0.1201733 , -0.06639934, -0.07080772, ...,  0.04945714,\n",
       "           -0.04745346,  0.06171324]], dtype=float32),\n",
       "   'returns': array([[ 0.00503825,  0.00488222,  0.00223422, ..., -0.00098351,\n",
       "            0.0051948 , -0.00177165],\n",
       "          [-0.01725422, -0.00605184,  0.0337073 , ...,  0.00591801,\n",
       "            0.0085866 ,  0.0018527 ],\n",
       "          [ 0.01053648,  0.01847604, -0.00888616, ..., -0.019949  ,\n",
       "           -0.02382839, -0.01833884],\n",
       "          ...,\n",
       "          [ 0.00219476, -0.00207312, -0.00014624, ...,  0.00114323,\n",
       "           -0.00323602,  0.00185499],\n",
       "          [-0.00645577, -0.00626588, -0.00475687, ...,  0.00295569,\n",
       "            0.00219498,  0.00299849],\n",
       "          [ 0.00612194,  0.00065968,  0.00303028, ..., -0.00385011,\n",
       "           -0.00806525, -0.00172601]], dtype=float32),\n",
       "   'returns_orig': array([[ 0.00503825,  0.00488222,  0.00223422, ..., -0.00098351,\n",
       "            0.0051948 , -0.00177165],\n",
       "          [-0.01725422, -0.00605184,  0.0337073 , ...,  0.00591801,\n",
       "            0.0085866 ,  0.0018527 ],\n",
       "          [ 0.01053648,  0.01847604, -0.00888616, ..., -0.019949  ,\n",
       "           -0.02382839, -0.01833884],\n",
       "          ...,\n",
       "          [ 0.00219476, -0.00207312, -0.00014624, ...,  0.00114323,\n",
       "           -0.00323602,  0.00185499],\n",
       "          [-0.00645577, -0.00626588, -0.00475687, ...,  0.00295569,\n",
       "            0.00219498,  0.00299849],\n",
       "          [ 0.00612194,  0.00065968,  0.00303028, ..., -0.00385011,\n",
       "           -0.00806525, -0.00172601]], dtype=float32),\n",
       "   'vols': array([[0.01648085, 0.0156077 , 0.0219312 , ..., 0.01295934, 0.0196045 ,\n",
       "           0.01680156],\n",
       "          [0.01624385, 0.01540688, 0.02157304, ..., 0.01274529, 0.01938653,\n",
       "           0.01653074],\n",
       "          [0.01701881, 0.01527559, 0.02504498, ..., 0.012638  , 0.01933061,\n",
       "           0.01627193],\n",
       "          ...,\n",
       "          [0.02115405, 0.01412546, 0.01710834, ..., 0.01026318, 0.01253692,\n",
       "           0.01240097],\n",
       "          [0.02081977, 0.01390943, 0.01682964, ..., 0.01009371, 0.01237511,\n",
       "           0.01219665],\n",
       "          [0.02064798, 0.01379403, 0.01665263, ..., 0.00993094, 0.01217338,\n",
       "           0.01200111]], dtype=float32)},\n",
       "  'test_dt': DatetimeIndex(['2021-01-04', '2021-01-05', '2021-01-06', '2021-01-07',\n",
       "                 '2021-01-08', '2021-01-11', '2021-01-12', '2021-01-13',\n",
       "                 '2021-01-14', '2021-01-15',\n",
       "                 ...\n",
       "                 '2021-12-17', '2021-12-20', '2021-12-21', '2021-12-22',\n",
       "                 '2021-12-23', '2021-12-27', '2021-12-28', '2021-12-29',\n",
       "                 '2021-12-30', '2021-12-31'],\n",
       "                dtype='datetime64[ns]', name='Date', length=252, freq=None)},\n",
       " Timestamp('2020-12-31 00:00:00', freq='365D'): {'val': {'preds': array([[ 0.15707596,  0.11329963,  0.12988275, ...,  0.00972935,\n",
       "            0.06794672,  0.05651759],\n",
       "          [ 0.04411306,  0.05187805,  0.07131898, ...,  0.09712612,\n",
       "            0.10809069,  0.0896955 ],\n",
       "          [ 0.04410752, -0.02560537, -0.09033523, ..., -0.02042385,\n",
       "            0.00603357,  0.02925725],\n",
       "          ...,\n",
       "          [-0.11184691,  0.06760693, -0.02217611, ...,  0.10022052,\n",
       "            0.10405055,  0.1513084 ],\n",
       "          [-0.12171409,  0.02117275, -0.05292251, ...,  0.07389776,\n",
       "            0.07632183,  0.11227934],\n",
       "          [-0.11063697,  0.07574378, -0.04556685, ...,  0.09905993,\n",
       "            0.08857595,  0.12674686]], dtype=float32),\n",
       "   'returns': array([[ 0.00503825,  0.00488222,  0.00223422, ..., -0.00098351,\n",
       "            0.0051948 , -0.00177165],\n",
       "          [-0.01725422, -0.00605184,  0.0337073 , ...,  0.00591801,\n",
       "            0.0085866 ,  0.0018527 ],\n",
       "          [ 0.01053648,  0.01847604, -0.00888616, ..., -0.019949  ,\n",
       "           -0.02382839, -0.01833884],\n",
       "          ...,\n",
       "          [ 0.00219476, -0.00207312, -0.00014624, ...,  0.00114323,\n",
       "           -0.00323602,  0.00185499],\n",
       "          [-0.00645577, -0.00626588, -0.00475687, ...,  0.00295569,\n",
       "            0.00219498,  0.00299849],\n",
       "          [ 0.00612194,  0.00065968,  0.00303028, ..., -0.00385011,\n",
       "           -0.00806525, -0.00172601]], dtype=float32),\n",
       "   'returns_orig': array([[ 0.00503825,  0.00488222,  0.00223422, ..., -0.00098351,\n",
       "            0.0051948 , -0.00177165],\n",
       "          [-0.01725422, -0.00605184,  0.0337073 , ...,  0.00591801,\n",
       "            0.0085866 ,  0.0018527 ],\n",
       "          [ 0.01053648,  0.01847604, -0.00888616, ..., -0.019949  ,\n",
       "           -0.02382839, -0.01833884],\n",
       "          ...,\n",
       "          [ 0.00219476, -0.00207312, -0.00014624, ...,  0.00114323,\n",
       "           -0.00323602,  0.00185499],\n",
       "          [-0.00645577, -0.00626588, -0.00475687, ...,  0.00295569,\n",
       "            0.00219498,  0.00299849],\n",
       "          [ 0.00612194,  0.00065968,  0.00303028, ..., -0.00385011,\n",
       "           -0.00806525, -0.00172601]], dtype=float32),\n",
       "   'vols': array([[0.01648085, 0.0156077 , 0.0219312 , ..., 0.01295934, 0.0196045 ,\n",
       "           0.01680156],\n",
       "          [0.01624385, 0.01540688, 0.02157304, ..., 0.01274529, 0.01938653,\n",
       "           0.01653074],\n",
       "          [0.01701881, 0.01527559, 0.02504498, ..., 0.012638  , 0.01933061,\n",
       "           0.01627193],\n",
       "          ...,\n",
       "          [0.02115405, 0.01412546, 0.01710834, ..., 0.01026318, 0.01253692,\n",
       "           0.01240097],\n",
       "          [0.02081977, 0.01390943, 0.01682964, ..., 0.01009371, 0.01237511,\n",
       "           0.01219665],\n",
       "          [0.02064798, 0.01379403, 0.01665263, ..., 0.00993094, 0.01217338,\n",
       "           0.01200111]], dtype=float32)},\n",
       "  'test': {'preds': array([[-0.12314939, -0.00079557, -0.09675276, ...,  0.06037591,\n",
       "            0.02026658,  0.07691144],\n",
       "          [-0.12856029,  0.01259063, -0.12234137, ...,  0.09229913,\n",
       "            0.06360079,  0.11004809],\n",
       "          [ 0.02645855,  0.0918926 ,  0.0230085 , ...,  0.03228086,\n",
       "            0.0210026 ,  0.10225374],\n",
       "          ...,\n",
       "          [-0.01095757,  0.0418836 , -0.05130345, ...,  0.1701212 ,\n",
       "           -0.01526428,  0.1222262 ],\n",
       "          [-0.09122349,  0.06025781, -0.08879744, ...,  0.16259208,\n",
       "            0.03013315,  0.11869404],\n",
       "          [-0.04542471,  0.02876441, -0.05304227, ...,  0.20555605,\n",
       "            0.04351747,  0.16171278]], dtype=float32),\n",
       "   'returns': array([[-0.00150809, -0.0028438 ,  0.01148261, ...,  0.00043428,\n",
       "           -0.00478284,  0.014409  ],\n",
       "          [-0.00635981, -0.03243236, -0.01734523, ...,  0.00904878,\n",
       "           -0.00171713,  0.00480762],\n",
       "          [-0.01765222, -0.00012141,  0.00826353, ..., -0.00318913,\n",
       "            0.00757399,  0.00573771],\n",
       "          ...,\n",
       "          [ 0.00834667,  0.01114906,  0.01073234, ...,  0.00412482,\n",
       "           -0.00087291, -0.0017156 ],\n",
       "          [-0.0024581 , -0.00097048, -0.00430119, ..., -0.00677669,\n",
       "           -0.01088257, -0.00532397],\n",
       "          [ 0.00393127,  0.00400209,  0.00779226, ..., -0.00052055,\n",
       "           -0.0096373 , -0.00336388]], dtype=float32),\n",
       "   'returns_orig': array([[-0.00150809, -0.0028438 ,  0.01148261, ...,  0.00043428,\n",
       "           -0.00478284,  0.014409  ],\n",
       "          [-0.00635981, -0.03243236, -0.01734523, ...,  0.00904878,\n",
       "           -0.00171713,  0.00480762],\n",
       "          [-0.01765222, -0.00012141,  0.00826353, ..., -0.00318913,\n",
       "            0.00757399,  0.00573771],\n",
       "          ...,\n",
       "          [ 0.00834667,  0.01114906,  0.01073234, ...,  0.00412482,\n",
       "           -0.00087291, -0.0017156 ],\n",
       "          [-0.0024581 , -0.00097048, -0.00430119, ..., -0.00677669,\n",
       "           -0.01088257, -0.00532397],\n",
       "          [ 0.00393127,  0.00400209,  0.00779226, ..., -0.00052055,\n",
       "           -0.0096373 , -0.00336388]], dtype=float32),\n",
       "   'vols': array([[0.02044586, 0.01356649, 0.01639264, ..., 0.00981973, 0.01215983,\n",
       "           0.01182465],\n",
       "          [0.02011955, 0.01336597, 0.0164565 , ..., 0.00965903, 0.01202903,\n",
       "           0.01199404],\n",
       "          [0.0199453 , 0.01553301, 0.01719496, ..., 0.00960324, 0.01184261,\n",
       "           0.01181638],\n",
       "          ...,\n",
       "          [0.01056908, 0.02394195, 0.01765159, ..., 0.01561469, 0.01418755,\n",
       "           0.01550357],\n",
       "          [0.01051645, 0.02421674, 0.0176637 , ..., 0.01539435, 0.01395851,\n",
       "           0.01525705],\n",
       "          [0.01036133, 0.02381648, 0.0174741 , ..., 0.0152938 , 0.01405814,\n",
       "           0.01508634]], dtype=float32)},\n",
       "  'test_dt': DatetimeIndex(['2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06',\n",
       "                 '2022-01-07', '2022-01-10', '2022-01-11', '2022-01-12',\n",
       "                 '2022-01-13', '2022-01-14',\n",
       "                 ...\n",
       "                 '2022-12-16', '2022-12-19', '2022-12-20', '2022-12-21',\n",
       "                 '2022-12-22', '2022-12-23', '2022-12-27', '2022-12-28',\n",
       "                 '2022-12-29', '2022-12-30'],\n",
       "                dtype='datetime64[ns]', name='Date', length=251, freq=None)},\n",
       " Timestamp('2021-12-31 00:00:00', freq='365D'): {'val': {'preds': array([[-0.11365669, -0.12171549, -0.1784849 , ..., -0.00343093,\n",
       "           -0.0913291 , -0.00645662],\n",
       "          [-0.09039942, -0.10911072, -0.1932262 , ...,  0.02139996,\n",
       "           -0.01854619,  0.00104052],\n",
       "          [-0.04349279, -0.09723485, -0.14773594, ..., -0.02271562,\n",
       "           -0.08027077, -0.00559743],\n",
       "          ...,\n",
       "          [ 0.06180043,  0.04770413, -0.01974777, ...,  0.15483724,\n",
       "            0.06683439,  0.14557135],\n",
       "          [ 0.00268   ,  0.0681178 , -0.04916565, ...,  0.11142791,\n",
       "            0.05023107,  0.13041687],\n",
       "          [ 0.03954221,  0.04837938, -0.00426841, ...,  0.19661324,\n",
       "            0.12641221,  0.2074757 ]], dtype=float32),\n",
       "   'returns': array([[-0.00150809, -0.0028438 ,  0.01148261, ...,  0.00043428,\n",
       "           -0.00478284,  0.014409  ],\n",
       "          [-0.00635981, -0.03243236, -0.01734523, ...,  0.00904878,\n",
       "           -0.00171713,  0.00480762],\n",
       "          [-0.01765222, -0.00012141,  0.00826353, ..., -0.00318913,\n",
       "            0.00757399,  0.00573771],\n",
       "          ...,\n",
       "          [ 0.00834667,  0.01114906,  0.01073234, ...,  0.00412482,\n",
       "           -0.00087291, -0.0017156 ],\n",
       "          [-0.0024581 , -0.00097048, -0.00430119, ..., -0.00677669,\n",
       "           -0.01088257, -0.00532397],\n",
       "          [ 0.00393127,  0.00400209,  0.00779226, ..., -0.00052055,\n",
       "           -0.0096373 , -0.00336388]], dtype=float32),\n",
       "   'returns_orig': array([[-0.00150809, -0.0028438 ,  0.01148261, ...,  0.00043428,\n",
       "           -0.00478284,  0.014409  ],\n",
       "          [-0.00635981, -0.03243236, -0.01734523, ...,  0.00904878,\n",
       "           -0.00171713,  0.00480762],\n",
       "          [-0.01765222, -0.00012141,  0.00826353, ..., -0.00318913,\n",
       "            0.00757399,  0.00573771],\n",
       "          ...,\n",
       "          [ 0.00834667,  0.01114906,  0.01073234, ...,  0.00412482,\n",
       "           -0.00087291, -0.0017156 ],\n",
       "          [-0.0024581 , -0.00097048, -0.00430119, ..., -0.00677669,\n",
       "           -0.01088257, -0.00532397],\n",
       "          [ 0.00393127,  0.00400209,  0.00779226, ..., -0.00052055,\n",
       "           -0.0096373 , -0.00336388]], dtype=float32),\n",
       "   'vols': array([[0.02044586, 0.01356649, 0.01639264, ..., 0.00981973, 0.01215983,\n",
       "           0.01182465],\n",
       "          [0.02011955, 0.01336597, 0.0164565 , ..., 0.00965903, 0.01202903,\n",
       "           0.01199404],\n",
       "          [0.0199453 , 0.01553301, 0.01719496, ..., 0.00960324, 0.01184261,\n",
       "           0.01181638],\n",
       "          ...,\n",
       "          [0.01056908, 0.02394195, 0.01765159, ..., 0.01561469, 0.01418755,\n",
       "           0.01550357],\n",
       "          [0.01051645, 0.02421674, 0.0176637 , ..., 0.01539435, 0.01395851,\n",
       "           0.01525705],\n",
       "          [0.01036133, 0.02381648, 0.0174741 , ..., 0.0152938 , 0.01405814,\n",
       "           0.01508634]], dtype=float32)},\n",
       "  'test': {'preds': array([[-0.04283111,  0.01945089, -0.03989106, ...,  0.18990155,\n",
       "            0.13660531,  0.17309743],\n",
       "          [-0.09173573, -0.0197455 , -0.09408265, ...,  0.12358222,\n",
       "            0.07159396,  0.15138702],\n",
       "          [ 0.0780291 ,  0.0757051 , -0.02111867, ...,  0.15914936,\n",
       "            0.12331773,  0.1832677 ],\n",
       "          ...,\n",
       "          [-0.00126649,  0.07744519, -0.04650513, ...,  0.15455543,\n",
       "            0.08118595,  0.13569061],\n",
       "          [-0.0058743 ,  0.05047391, -0.04261409, ...,  0.16699289,\n",
       "            0.0930043 ,  0.1490726 ],\n",
       "          [-0.00268941,  0.03913261,  0.01332635, ...,  0.16225775,\n",
       "            0.10549169,  0.16521272]], dtype=float32),\n",
       "   'returns': array([[-4.8144755e-04, -4.6868362e-03,  1.4687275e-02, ...,\n",
       "            4.3035639e-03,  2.0444754e-03,  5.4995948e-03],\n",
       "          [ 1.4690118e-03, -8.6912159e-03,  8.2030874e-03, ...,\n",
       "           -1.1600643e-02, -1.5415083e-02, -1.0606897e-02],\n",
       "          [ 7.8286249e-03,  5.4142880e-03,  7.2301012e-03, ...,\n",
       "            1.8490134e-02,  2.3179153e-02,  8.6454889e-03],\n",
       "          ...,\n",
       "          [ 0.0000000e+00,  5.3917817e-03,  1.1815400e-03, ...,\n",
       "           -2.1337559e-03, -6.9366782e-03, -1.1286764e-02],\n",
       "          [ 7.7792567e-05,  1.1985762e-03,  5.1233787e-08, ...,\n",
       "           -1.1901883e-02, -1.0081939e-03, -8.3232420e-03],\n",
       "          [ 3.9561003e-04, -2.1386447e-03, -1.3658049e-04, ...,\n",
       "           -1.0156722e-02, -8.2097426e-03, -2.1452222e-03]], dtype=float32),\n",
       "   'returns_orig': array([[-4.8144755e-04, -4.6868362e-03,  1.4687275e-02, ...,\n",
       "            4.3035639e-03,  2.0444754e-03,  5.4995948e-03],\n",
       "          [ 1.4690118e-03, -8.6912159e-03,  8.2030874e-03, ...,\n",
       "           -1.1600643e-02, -1.5415083e-02, -1.0606897e-02],\n",
       "          [ 7.8286249e-03,  5.4142880e-03,  7.2301012e-03, ...,\n",
       "            1.8490134e-02,  2.3179153e-02,  8.6454889e-03],\n",
       "          ...,\n",
       "          [ 0.0000000e+00,  5.3917817e-03,  1.1815400e-03, ...,\n",
       "           -2.1337559e-03, -6.9366782e-03, -1.1286764e-02],\n",
       "          [ 7.7792567e-05,  1.1985762e-03,  5.1233787e-08, ...,\n",
       "           -1.1901883e-02, -1.0081939e-03, -8.3232420e-03],\n",
       "          [ 3.9561003e-04, -2.1386447e-03, -1.3658049e-04, ...,\n",
       "           -1.0156722e-02, -8.2097426e-03, -2.1452222e-03]], dtype=float32),\n",
       "   'vols': array([[0.01021163, 0.02352717, 0.01732611, ..., 0.01504328, 0.0140715 ,\n",
       "           0.01486642],\n",
       "          [0.01004537, 0.02320556, 0.01759389, ..., 0.01483757, 0.01385143,\n",
       "           0.01470945],\n",
       "          [0.00988054, 0.02308059, 0.01743538, ..., 0.01498553, 0.01420747,\n",
       "           0.01476569],\n",
       "          ...,\n",
       "          [0.01341664, 0.01706007, 0.02192204, ..., 0.01056602, 0.01016921,\n",
       "           0.01004016],\n",
       "          [0.01319839, 0.0168251 , 0.02157466, ..., 0.01039369, 0.01007077,\n",
       "           0.01009479],\n",
       "          [0.01298314, 0.01654765, 0.02121995, ..., 0.01044255, 0.0099043 ,\n",
       "           0.01003663]], dtype=float32)},\n",
       "  'test_dt': DatetimeIndex(['2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06',\n",
       "                 '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12',\n",
       "                 '2023-01-13', '2023-01-17',\n",
       "                 ...\n",
       "                 '2023-08-18', '2023-08-21', '2023-08-22', '2023-08-23',\n",
       "                 '2023-08-24', '2023-08-25', '2023-08-28', '2023-08-29',\n",
       "                 '2023-08-30', '2023-08-31'],\n",
       "                dtype='datetime64[ns]', name='Date', length=167, freq=None)}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a2b6d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5797e-03,  3.7085e-04, -3.2144e-03,  ..., -8.8253e-03,\n",
       "         -5.5738e-03, -7.6499e-03],\n",
       "        [-4.4201e-03,  5.9013e-03,  3.8420e-03,  ...,  8.9822e-05,\n",
       "          5.0745e-03, -2.9620e-03],\n",
       "        [ 6.8760e-03,  7.9661e-04,  4.4505e-03,  ..., -5.1095e-03,\n",
       "          2.1016e-03, -3.1893e-03],\n",
       "        ...,\n",
       "        [-2.2367e-03, -2.9538e-03, -1.8163e-03,  ..., -9.4694e-03,\n",
       "          5.8776e-04, -4.8728e-04],\n",
       "        [ 2.2782e-03, -1.4484e-02,  3.1967e-03,  ...,  4.6133e-04,\n",
       "         -5.9723e-04,  1.9829e-03],\n",
       "        [ 7.0853e-02,  3.3031e-03,  1.2235e-02,  ...,  1.5749e-02,\n",
       "          1.2759e-02,  1.5639e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "967c7909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0045,  0.0007, -0.0058,  ..., -0.0118, -0.0065, -0.0093],\n",
       "        [-0.0076,  0.0115,  0.0068,  ...,  0.0001,  0.0059, -0.0036],\n",
       "        [ 0.0117,  0.0015,  0.0078,  ..., -0.0067,  0.0024, -0.0038],\n",
       "        ...,\n",
       "        [-0.0033, -0.0052, -0.0029,  ..., -0.0122,  0.0007, -0.0006],\n",
       "        [ 0.0033, -0.0254,  0.0050,  ...,  0.0006, -0.0007,  0.0022],\n",
       "        [ 0.1002,  0.0059,  0.0189,  ...,  0.0199,  0.0143,  0.0172]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y_orig[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f74a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['test']['preds'] = test_preds\n",
    "results['test']['returns'] = test_returns\n",
    "results['test']['returns_orig'] = test_returns_orig\n",
    "results['test']['vols'] = test_vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ecdced7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83383634, 0.51192949, 0.28745112, ..., 0.18885391, 1.07419992,\n",
       "        1.04470401],\n",
       "       [0.67396717, 0.55053077, 0.53674765, ..., 0.62509811, 0.56359869,\n",
       "        0.24428089],\n",
       "       [0.32709056, 0.61189209, 0.3497896 , ..., 0.01410749, 0.66190774,\n",
       "        0.9456643 ],\n",
       "       ...,\n",
       "       [0.87709293, 0.57821921, 0.4666867 , ..., 0.39466517, 0.78080213,\n",
       "        0.70181444],\n",
       "       [0.03822577, 0.38370012, 0.83944019, ..., 0.0178256 , 0.54594523,\n",
       "        0.74240624],\n",
       "       [0.57244881, 0.2677478 , 0.34134158, ..., 0.32640767, 0.57954612,\n",
       "        0.71406727]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e6b548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_y_orig, batch_vol = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6f997f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 21, 440]), torch.Size([64, 21, 55]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape, batch_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fe61f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8374)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b068f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.7343)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92ca13d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 21, 55]), torch.Size([64, 21, 55]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape, batch_y_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "607c5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LSTMnet(batch_x.shape[2], batch_y.shape[2], batch_x.shape[1])\n",
    "#model = SLP(batch_x.shape[2], batch_y.shape[2], batch_x.shape[1])\n",
    "#model = MLP(batch_x.shape[2], batch_y.shape[2], batch_x.shape[1])\n",
    "model = TCN(batch_x.shape[2], batch_y.shape[2], batch_x.shape[1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = []\n",
    "val_returns = []\n",
    "val_returns_orig = []\n",
    "val_vols = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_y_orig, batch_vol in val_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_y_orig = batch_y_orig.to(device)\n",
    "        batch_vol = batch_vol.to(device)\n",
    "\n",
    "        output = model(batch_x)\n",
    "\n",
    "\n",
    "        # select last timestep as we no longer need for time axis in batch\n",
    "        val_returns.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "        val_returns_orig.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "        val_preds.append(output[:, -1, :].detach().cpu().numpy())\n",
    "        val_vols.append(batch_vol[:, -1, :].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "val_preds = np.concatenate(val_preds)\n",
    "val_returns = np.concatenate(val_returns)\n",
    "val_returns_orig = np.concatenate(val_returns_orig)\n",
    "val_vols = np.concatenate(val_vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "test_returns = []\n",
    "test_returns_orig = []\n",
    "test_vols = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_y_orig, batch_vol in test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        batch_y_orig = batch_y_orig.to(device)\n",
    "        batch_vol = batch_vol.to(device)\n",
    "\n",
    "        output = model(batch_x)\n",
    "\n",
    "\n",
    "        # select last timestep as we no longer need for time axis in batch\n",
    "        test_returns.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "        test_returns_orig.append(batch_y[:, -1, :].detach().cpu().numpy())\n",
    "        test_preds.append(output[:, -1, :].detach().cpu().numpy())\n",
    "        test_vols.append(batch_vol[:, -1, :].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_returns = np.concatenate(test_returns)\n",
    "test_returns_orig = np.concatenate(test_returns_orig)\n",
    "test_vols = np.concatenate(test_vols)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
